{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb3db74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras-unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150a1f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import shutil\n",
    "import random\n",
    "import inspect\n",
    "#import imageio as im\n",
    "import numpy as np\n",
    "import mahotas as mh\n",
    "from PIL import Image\n",
    "from tabulate import tabulate\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "#from skimage import measure, filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef84d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original directory path and working directory path for images\n",
    "data = \"/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir/raw_files\"\n",
    "working_dir = \"/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir\"\n",
    "######################################################################################################\n",
    "experiment = \"test2\" \n",
    "######################################################################################################\n",
    "real = f\"{working_dir}/{experiment}/real_images\"\n",
    "#########################################################################################################\n",
    "\n",
    "directories = {\n",
    "    \"normalized\": f\"{working_dir}/{experiment}/normalized_images\",\n",
    "    \"cropped\": f\"{working_dir}/{experiment}/cropped_images\",\n",
    "    \"npy\": f\"{working_dir}/{experiment}/pre_processing/npy\",\n",
    "    \"originals\": f\"{working_dir}/{experiment}/pre_processing/originals\",\n",
    "    \"masks\": f\"{working_dir}/{experiment}/pre_processing/masks\",\n",
    "    \"test\": f\"{working_dir}/{experiment}/pre_processing/test\",\n",
    "    \"s\": f\"{working_dir}/{experiment}/S\",\n",
    "    \"crop_original\": f\"{working_dir}/{experiment}/pre_processing/crop_originals\",\n",
    "    \"crop_masks\": f\"{working_dir}/{experiment}/pre_processing/crop_masks\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a691756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras_unet.models import custom_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4884f7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "npy = f\"{working_dir}/{experiment}/pre_processing/npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54edae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine = f\"{working_dir}/{experiment}/pre_processing/machine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712fabc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_file = os.path.join(npy, 'original.npy')\n",
    "labels_file = os.path.join(npy, 'mask.npy')\n",
    "#test_files = os.path.join(npy, 'test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c666dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load(images_file)\n",
    "labels = np.load(labels_file)\n",
    "#test = np.load(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68111694",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfb1855",
   "metadata": {},
   "outputs": [],
   "source": [
    " # full dataset does not have the last channel\n",
    "images = images.reshape(images.shape[0],images.shape[1],images.shape[2],1)\n",
    "labels = labels.reshape(labels.shape[0],labels.shape[1],labels.shape[2],1)\n",
    "#test = test.reshape(test.shape[0],test.shape[1],test.shape[2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297420b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71e7668",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c495ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.random.permutation(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2283d8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images[p]\n",
    "labels = labels[p]\n",
    "#test = test[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f342762",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc746342",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.astype(np.float64)\n",
    "for i in range(images.shape[0]):\n",
    "    images[i] = (images[i] - images[i].min()) / (images[i].max() - images[i].min()) # normalize individually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d25d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a79e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = images[0:1200]\n",
    "y_train = labels[0:1200]\n",
    "X_val = images[1201:1700]\n",
    "y_val = labels[1201:1700]\n",
    "X_test = images[1701:1812]\n",
    "y_test = labels[1701:1812]\n",
    "\n",
    "#X_test = test[80:]\n",
    "#y_test = test[80:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a1ba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510c5e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################  MODEL -1######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d655d20e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = custom_unet(\n",
    "    input_shape=(512, 512, 1),\n",
    "    use_batch_norm=False,\n",
    "    num_classes=1,\n",
    "    filters=32,\n",
    "    dropout=0.5,\n",
    "    output_activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80709342",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################     MODEL - 2#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c1cfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import Model\n",
    "# from keras import regularizers\n",
    "# from keras.layers import Conv2D\n",
    "\n",
    "# # Create the custom_unet model\n",
    "# unet_model = custom_unet(\n",
    "#     input_shape=(512, 512, 1),\n",
    "#     use_batch_norm=False,\n",
    "#     num_classes=1,\n",
    "#     filters=32,\n",
    "#     dropout=0.5,\n",
    "#     output_activation='sigmoid')\n",
    "\n",
    "# # Add a Conv2D layer with L1 and L2 regularization on top of the custom_unet model\n",
    "# x = Conv2D(filters=64,\n",
    "#            kernel_size=(3, 3),\n",
    "#            kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01),\n",
    "#            bias_regularizer=regularizers.l2(0.01))(unet_model.output)\n",
    "\n",
    "# # Create a new model that includes the custom_unet model and the additional layer\n",
    "# model = Model(inputs=unet_model.input, outputs=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509b5258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.optimizers\n",
    "from keras_unet.metrics import iou, iou_thresholded\n",
    "from keras_unet.losses import jaccard_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c25b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6136c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizer_v1.Adam(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93d09ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'Adam',    \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=[iou, iou_thresholded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6b24cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### batch size 50 , epochs =1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113f685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def training(batch,epochs):\n",
    "#     print (\"training and prediction for\",\"batch size:  \",batch, \"epochs:  \", epochs)\n",
    "#     history = model.fit(X_train, \n",
    "#                     y_train, \n",
    "#                     batch, \n",
    "#                     epochs=epochs,\n",
    "#                     validation_data=(X_val, y_val), \n",
    "#                     verbose=1)\n",
    "    \n",
    "#     from keras_unet.utils import plot_segm_history\n",
    "\n",
    "#     plot_segm_history(history)\n",
    "    \n",
    "#     y_pred = model.predict(X_test)\n",
    "    \n",
    "#     from keras_unet.utils import plot_imgs\n",
    "\n",
    "#     plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred, nm_img_to_plot=100)# number to plot also need to e defined in function\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfa0ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_unet.utils import plot_segm_history, plot_imgs\n",
    "\n",
    "def training(batch, epochs):\n",
    "    print(\"training and prediction for\", \"batch size: \", batch, \"epochs: \", epochs)\n",
    "\n",
    "#     # Regularization\n",
    "#     layer = Dense(units=64,\n",
    "#                   kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01),\n",
    "#                   bias_regularizer=regularizers.l2(0.01))\n",
    "\n",
    "    # Early stopping\n",
    "    #early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "#     # Data augmentation\n",
    "#     datagen = ImageDataGenerator(rotation_range=20,\n",
    "#                                  width_shift_range=0.2,\n",
    "#                                  height_shift_range=0.2,\n",
    "#                                  horizontal_flip=True)\n",
    "#     datagen.fit(X_train)\n",
    "\n",
    "#     # Training with data augmentation\n",
    "#     history = model.fit(datagen.flow(X_train, y_train, batch_size=batch),\n",
    "#                         steps_per_epoch=len(X_train) / batch,\n",
    "#                         epochs=epochs,\n",
    "#                         validation_data=(X_val, y_val),\n",
    "#                         callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "########################################ONLY EARLY STOPPING###################################\n",
    "    # Early stopping\n",
    "    #early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "    # Training with early stopping\n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        batch_size=batch,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(X_val, y_val))\n",
    "                        \n",
    "\n",
    "    # Plotting results\n",
    "    plot_segm_history(history)\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Apply thresholding\n",
    "    threshold = 5.0\n",
    "    y_pred_binary = (y_pred > threshold).astype(np.uint8)\n",
    "    plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred, nm_img_to_plot=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b197bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_unet.utils import plot_segm_history, plot_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0002b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_unet.utils import plot_segm_history, plot_imgs\n",
    "\n",
    "def trainingearlystopping(batch, epochs):\n",
    "    print(\"training and prediction for\", \"batch size: \", batch, \"epochs: \", epochs)\n",
    "########################################ONLY EARLY STOPPING###################################\n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "    # Training with early stopping\n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        batch_size=batch,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        callbacks=[early_stopping])\n",
    "\n",
    "    # Plotting results\n",
    "    plot_segm_history(history)\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Apply thresholding\n",
    "    threshold = 0.2\n",
    "    y_pred_binary = (y_pred > threshold).astype(np.uint8)\n",
    "    plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred, nm_img_to_plot=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9145fc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training(60,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b761d877",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training(60,800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6358db50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainingearlystopping(60,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff79002",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingearlystopping(60,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11feebf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ TRYING THRESHOLD VALUES\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def trainingwiththres(batch, epochs, thresholds, n_images):\n",
    "    print(\"training and prediction for\", \"batch size: \", batch, \"epochs: \", epochs)\n",
    "\n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "    # Training with early stopping\n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        batch_size=batch,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        callbacks=[early_stopping])\n",
    "\n",
    "    # Plotting results\n",
    "    plot_segm_history(history)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Apply multiple thresholds\n",
    "    y_pred_binaries = []\n",
    "    for threshold in thresholds:\n",
    "        y_pred_binary = (y_pred > threshold).astype(np.uint8)\n",
    "        y_pred_binaries.append(y_pred_binary)\n",
    "\n",
    "    # Plot binary masks for multiple thresholds\n",
    "    fig, axes = plt.subplots(n_images, len(thresholds), figsize=(15, 15))\n",
    "    for i in range(n_images):\n",
    "        for j in range(len(thresholds)):\n",
    "            axes[i][j].imshow(y_pred_binaries[j][i])\n",
    "            axes[i][j].set_title(f'Threshold {thresholds[j]}')\n",
    "            axes[i][j].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e72ae8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "thresholds = [0.2, 0.4, 0.6, 0.8]\n",
    "n_images = 10\n",
    "history = trainingwiththres(60, 100, thresholds, n_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58aefbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db0559b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcbf20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from keras.metrics import MeanIoU\n",
    "\n",
    "n_classes = 2 # number of classes in your segmentation masks\n",
    "IoU = MeanIoU(num_classes=n_classes)\n",
    "\n",
    "model = Sequential()\n",
    "# Encoder\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(512, 512, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "\n",
    "# Decoder\n",
    "model.add(Conv2DTranspose(128, (3, 3), strides=(2, 2), activation='relu', padding='same'))\n",
    "model.add(Conv2DTranspose(64, (3, 3), strides=(2, 2), activation='relu', padding='same'))\n",
    "model.add(Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[IoU])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d802ccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the data\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    batch_size=60,\n",
    "                    epochs=100,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f602dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " # Plotting results\n",
    "from keras_unet.utils import plot_segm_history\n",
    "\n",
    "metrics = ['loss', 'val_loss', 'mean_io_u_1', 'val_mean_io_u_1']\n",
    "plot_segm_history(history, metrics=metrics)\n",
    "y_pred = model.predict(X_test)\n",
    "# Apply thresholding\n",
    "\n",
    "#y_pred_binary = (y_pred > threshold).astype(np.uint8)\n",
    "plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred, nm_img_to_plot=90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37702fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelFCN(): #Fully Convolutional Network (FCN\n",
    "  from keras import regularizers\n",
    "  from keras.models import Sequential\n",
    "  from keras.layers import Dense\n",
    "  from keras.callbacks import EarlyStopping\n",
    "  from keras.preprocessing.image import ImageDataGenerator\n",
    "  from keras_unet.utils import plot_segm_history, plot_imgs\n",
    "  from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "  from keras.metrics import MeanIoU\n",
    "\n",
    "  n_classes = 2 # number of classes in your segmentation masks\n",
    "  IoU = MeanIoU(num_classes=n_classes)\n",
    "\n",
    "  model = Sequential()\n",
    "  # Encoder\n",
    "  model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(512, 512, 1)))\n",
    "  model.add(MaxPooling2D((2, 2)))\n",
    "  model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "  model.add(MaxPooling2D((2, 2)))\n",
    "  model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "\n",
    "  # Decoder\n",
    "  model.add(Conv2DTranspose(128, (3, 3), strides=(2, 2), activation='relu', padding='same'))\n",
    "  model.add(Conv2DTranspose(64, (3, 3), strides=(2, 2), activation='relu', padding='same'))\n",
    "  model.add(Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same'))\n",
    "\n",
    "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[IoU])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01426b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newtrain(batch,epochs,plot):\n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        batch_size=batch,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(X_val, y_val))\n",
    "         # Plotting results\n",
    "    from keras_unet.utils import plot_segm_history\n",
    "\n",
    "    metrics = ['loss', 'val_loss', 'mean_io_u', 'val_mean_io_u']\n",
    "    plot_segm_history(history, metrics=metrics)\n",
    "    y_pred = model.predict(X_test)   \n",
    "    # Apply thresholding\n",
    "    #y_pred_binary = (y_pred > threshold).astype(np.uint8)\n",
    "    plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred, nm_img_to_plot=plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d14ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nt_early(batch,epochs,plot):\n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=20)     \n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        batch_size=batch,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        callbacks=[early_stopping])\n",
    "         # Plotting results\n",
    "    from keras_unet.utils import plot_segm_history\n",
    "\n",
    "    metrics = ['loss', 'val_loss', 'mean_io_u', 'val_mean_io_u']\n",
    "    plot_segm_history(history, metrics=metrics)\n",
    "    y_pred = model.predict(X_test)   \n",
    "    # Apply thresholding\n",
    "    #threshold = 0.7\n",
    "    #y_pred = (y_pred > threshold).astype(np.uint8)\n",
    "    plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred, nm_img_to_plot=plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2596a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#newtrain(60,4000,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415685b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#newtrain(60,400,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a6d525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nt_early_pp(batch,epochs,plot,thres):\n",
    "    import cv2\n",
    "    from PIL import Image\n",
    "    # Early stopping\n",
    "    #early_stopping = EarlyStopping(monitor='val_loss', patience=20)     \n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        batch_size=batch,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(X_val, y_val))#,\n",
    "                        #callbacks=[early_stopping])\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Apply thresholding to the predicted images\n",
    "    threshold = thres # set threshold value\n",
    "    y_pred = (y_pred > threshold).astype(np.uint8)\n",
    "    # Apply contrast stretching to the predicted images\n",
    "    new_min_value = 0\n",
    "    new_max_value = 255\n",
    "\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        #print(y_pred[i].shape)\n",
    "        #print(y_pred[i].dtype)\n",
    "        image = Image.fromarray((y_pred[i].squeeze() * 255).astype(np.uint8))\n",
    "        min_value, max_value = image.getextrema()\n",
    "        scale = (new_max_value - new_min_value) / (max_value - min_value)\n",
    "        image = image.point(lambda i: (i - min_value) * scale + new_min_value)\n",
    "        y_pred[i] = np.expand_dims(np.array(image), axis=-1) / 255\n",
    "        \n",
    "    # Plotting results\n",
    "    from keras_unet.utils import plot_segm_history\n",
    "\n",
    "    metrics = ['loss', 'val_loss', 'mean_io_u', 'val_mean_io_u']\n",
    "    plot_segm_history(history, metrics=metrics)   \n",
    "    plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred, nm_img_to_plot=plot)\n",
    "    # Threshold the predicted segmentation mask\n",
    "    #threshold = 0.5\n",
    "    #y_pred_binary = (y_pred > threshold).astype(np.uint8)\n",
    "    \n",
    "    # Check if the shapes of y_pred_binary and labels are the same\n",
    "#     print(y_pred_binary.shape)\n",
    "#     print(X_test.shape)\n",
    "#     print(y_train.shape)\n",
    "#     print(X_train.shape)\n",
    "#     if y_pred_binary.shape != X_test.shape:\n",
    "#         # Resize labels to match the shape of y_pred_binary\n",
    "#         labels = cv2.resize(labels, (y_pred_binary.shape[1], y_pred_binary.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "#     # Apply connected component analysis to remove small connected components\n",
    "#     num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(y_pred_binary)\n",
    "\n",
    "#     # Find the largest connected component (excluding the background label)\n",
    "#     largest_label = np.argmax(stats[1:, cv2.CC_STAT_AREA]) + 1\n",
    "\n",
    "#     # Create a new mask containing only the largest connected component\n",
    "#     y_pred_filtered = np.zeros_like(y_pred_binary)\n",
    "#     y_pred_filtered[labels == largest_label] = 1\n",
    "\n",
    "#     # Plot the filtered mask\n",
    "#     plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred_filtered, nm_img_to_plot=plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd8f1ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf20a4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nt_early_pp(60,20,50,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68bbb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nt_early_pp(60,20,50,0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539c5f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "nt_early_pp(60,20,50,0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff7e4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nt_early_pp(60,20,50,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2e9876",
   "metadata": {},
   "outputs": [],
   "source": [
    "nt_early_pp(60,20,50,0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8312132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "save_dir = machine\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "def nt_early_pp(batch,epochs,plot,thres):\n",
    "    import cv2\n",
    "    from PIL import Image\n",
    "    \n",
    "    # Early stopping\n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        batch_size=batch,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(X_val, y_val))\n",
    "    \n",
    "    # Make predictions and apply thresholding\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = (y_pred > thres).astype(np.uint8)\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score\n",
    "    report = classification_report(y_test.flatten(), y_pred.flatten(), target_names=['background', 'circle'], output_dict=True)\n",
    "    print('Classification report:\\n', report)\n",
    "    \n",
    "    # Apply contrast stretching to the predicted images\n",
    "    new_min_value = 0\n",
    "    new_max_value = 255\n",
    "\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        image = Image.fromarray((y_pred[i].squeeze() * 255).astype(np.uint8))\n",
    "        min_value, max_value = image.getextrema()\n",
    "        scale = (new_max_value - new_min_value) / (max_value - min_value)\n",
    "        image = image.point(lambda i: (i - min_value) * scale + new_min_value)\n",
    "        y_pred[i] = np.expand_dims(np.array(image), axis=-1) / 255\n",
    "        \n",
    "    # Plotting results\n",
    "    from keras_unet.utils import plot_segm_history\n",
    "    save_path = os.path.join(save_dir, f'image_{i}.png')\n",
    "    cv2.imwrite(save_path, y_pred)\n",
    "\n",
    "    metrics = ['loss', 'val_loss', 'mean_io_u', 'val_mean_io_u']\n",
    "    plot_segm_history(history, metrics=metrics)   \n",
    "    plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred, nm_img_to_plot=plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0b1a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def nt_early_pp(batch,epochs,plot,thres):\n",
    "    import cv2\n",
    "    from PIL import Image\n",
    "    \n",
    "    # Early stopping\n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        batch_size=batch,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(X_val, y_val))\n",
    "    \n",
    "    # Make predictions and apply thresholding\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = (y_pred > thres).astype(np.uint8)\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score\n",
    "    report = classification_report(y_test.flatten(), y_pred.flatten(), target_names=['background', 'circle'], output_dict=True)\n",
    "    print('Classification report:\\n', report)\n",
    "    \n",
    "    # Apply contrast stretching to the predicted images\n",
    "    new_min_value = 0\n",
    "    new_max_value = 255\n",
    "\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        image = Image.fromarray((y_pred[i].squeeze() * 255).astype(np.uint8))\n",
    "        min_value, max_value = image.getextrema()\n",
    "        scale = (new_max_value - new_min_value) / (max_value - min_value)\n",
    "        image = image.point(lambda i: (i - min_value) * scale + new_min_value)\n",
    "        y_pred[i] = np.expand_dims(np.array(image), axis=-1) / 255\n",
    "        \n",
    "    # Plotting results\n",
    "    from keras_unet.utils import plot_segm_history\n",
    "\n",
    "    metrics = ['loss', 'val_loss', 'mean_io_u', 'val_mean_io_u']\n",
    "    plot_segm_history(history, metrics=metrics)   \n",
    "    plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred, nm_img_to_plot=plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25ccb1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98203308",
   "metadata": {},
   "outputs": [],
   "source": [
    "nt_early_pp(60,200,50,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923677c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nt_early_pp(60,200,50,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b5fa20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d87ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nt_early_pp(60,200,50,0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aad8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "nt_early_pp(60,200,50,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3209c17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nt_early_pp(60,200,50,0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febdcfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nt_early_pp(60,200,50,0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a42bdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nt_early_pp(60,800,100,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e817fe9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2471529d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b270daef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a1227d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b2f966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f89735",
   "metadata": {},
   "outputs": [],
   "source": [
    "nt_early_pp(60,2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6443afa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nt_early(60,400,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4652d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        batch_size=60,\n",
    "                        epochs=4,\n",
    "                        validation_data=(X_val, y_val))\n",
    "         # Plotting results\n",
    "from keras_unet.utils import plot_segm_history\n",
    "\n",
    "metrics = ['loss', 'val_loss', 'mean_io_u', 'val_mean_io_u']\n",
    "plot_segm_history(history, metrics=metrics)\n",
    "y_pred = model.predict(X_test)   \n",
    "# Apply thresholding\n",
    "threshold = 0.9\n",
    "y_pred_binary = (y_pred > threshold).astype(np.uint8)\n",
    "plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred, nm_img_to_plot=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2410b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6788c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d644a6b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadf9ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fcb3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training history\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Apply thresholding\n",
    "threshold = 5.0\n",
    "y_pred_binary = (y_pred > threshold).astype(np.uint8)\n",
    "\n",
    "# Plot segmentation results\n",
    "n = 3 # number of images to plot\n",
    "for i in range(n):\n",
    "    plt.subplot(1, n, i+1)\n",
    "    plt.imshow(y_pred_binary[i,:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c30a50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f8c72c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e52631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba311bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967e9a45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a04400e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b077b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#training(60,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46d5fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# a little overlifting has been noticed in the above graph so we are using new techiniques to decrease that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c589d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training(60,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31ebb9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cab8945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7470ba18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c658588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7fdf01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9c72b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84af0363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc49fda0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f13d9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0972bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2de846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603eeb77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d343dff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2b098e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    50, \n",
    "                    epochs=1000,\n",
    "                    validation_data=(X_val, y_val), \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847076ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_unet.utils import plot_segm_history\n",
    "\n",
    "plot_segm_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89f181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1d5c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_unet.utils import plot_imgs\n",
    "\n",
    "plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred, nm_img_to_plot=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5afdbe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0faf44",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training(60,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cf401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf761767",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training(65,65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4bcf86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "overlay(directories['originals'],directories['masks'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c30a823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf6b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "training(60,4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbeb5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training(64,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4261465b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e02d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa5006b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87843d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "def overlay(original_dir, mask_dir, n):\n",
    "    original_images = os.listdir(original_dir)\n",
    "    mask_images = os.listdir(mask_dir)\n",
    "\n",
    "    for i in range(n):\n",
    "        original_image = random.choice(original_images)\n",
    "        mask_image = original_image.replace('.png', '_mask.png')\n",
    "        if mask_image in mask_images:\n",
    "            img = Image.open(os.path.join(original_dir, original_image))\n",
    "            mask = Image.open(os.path.join(mask_dir, mask_image))\n",
    "            img.paste(mask, (0, 0), mask)\n",
    "            img.show()\n",
    "            #hint: # overlay_masks('original', 'masks', 3) - To plot overlay wiht masks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91cce3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras-unet\n",
    "\n",
    "# import keras\n",
    "# from keras_unet.models import custom_unet\n",
    "\n",
    "# images_file = os.path.join(npy_files, 'original.npy')\n",
    "# labels_file = os.path.join(npy_files, 'mask.npy')\n",
    "\n",
    "# images = np.load(images_file)\n",
    "# labels = np.load(labels_file)\n",
    "\n",
    "# images.shape\n",
    "\n",
    "# # full dataset does not have the last channel\n",
    "# images = images.reshape(images.shape[0],images.shape[1],images.shape[2],1)\n",
    "# labels = labels.reshape(labels.shape[0],labels.shape[1],labels.shape[2],1)\n",
    "\n",
    "# images.shape\n",
    "\n",
    "# p = np.random.permutation(len(images))\n",
    "\n",
    "# images = images[p]\n",
    "# labels = labels[p]\n",
    "\n",
    "# labels = labels.astype(np.float64)\n",
    "\n",
    "# images = images.astype(np.float64)\n",
    "\n",
    "# for i in range(images.shape[0]):\n",
    "#     images[i] = (images[i] - images[i].min()) / (images[i].max() - images[i].min()) # normalize individually\n",
    "\n",
    "\n",
    "# images.shape\n",
    "\n",
    "# X_train = images[0:50]\n",
    "# y_train = labels[0:50]\n",
    "# X_val = images[10:20]\n",
    "# y_val = labels[10:20]\n",
    "# X_test = images[0:]\n",
    "# y_test = labels[0:]\n",
    "\n",
    "# model = custom_unet(\n",
    "#     input_shape=(512, 512, 1),\n",
    "#     use_batch_norm=False,\n",
    "#     num_classes=1,\n",
    "#     filters=32,\n",
    "#     dropout=0.5,\n",
    "#     output_activation='sigmoid')\n",
    "\n",
    "# import keras.optimizers\n",
    "# from keras_unet.metrics import iou, iou_thresholded\n",
    "# from keras_unet.losses import jaccard_distance\n",
    "\n",
    "\n",
    "\n",
    "# opt = keras.optimizer_v1.Adam(lr=0.01)\n",
    "\n",
    "# model.compile(optimizer = 'Adam',    \n",
    "#               loss='binary_crossentropy', \n",
    "#               metrics=[iou, iou_thresholded])\n",
    "\n",
    "# history = model.fit(X_train, \n",
    "#                     y_train, \n",
    "#                     50, \n",
    "#                     epochs=500,\n",
    "#                     validation_data=(X_val, y_val), \n",
    "#                     verbose=1)\n",
    "\n",
    "# from keras_unet.utils import plot_segm_history\n",
    "\n",
    "# plot_segm_history(history)\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# from keras_unet.utils import plot_imgs\n",
    "\n",
    "# plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred, nm_img_to_plot=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef9bf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My next idea in the pipe line is to compare same images on different iterations and come to conclusion.\n",
    "# To decide what batch size and epochs gives the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdb788f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
