{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9dd344",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## GPU  BASED ITERATION SEGMENTATION USING TRADITIONAL COMPUTER VISION ##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b8002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pillow\n",
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2c49d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNISNSTALL EXISTING NUMPY MAHATOS AND RE-INSALL IT BEFORE RUNNING THIS ?make sure you have a numpy1.24 or above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0b6b9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip uninstall numpy mahotas -y     ## run this two times just to make sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3906d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall numpy mahotas -y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fcb7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy mahotas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5ea222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import shutil\n",
    "import random\n",
    "import inspect\n",
    "#import imageio as im\n",
    "import numpy as np\n",
    "import mahotas as mh\n",
    "from PIL import Image\n",
    "from tabulate import tabulate\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "#from skimage import measure, filters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e3697d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604a46b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade mahotas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04f265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### EXCEPT FOR RAW DATA I ALWAYS USE FRESH DIRECTORIES #############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9435e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original directory path and working directory path for images\n",
    "data = \"/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir/raw_files\"\n",
    "working_dir = \"/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af442e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### THE BELOW ARE TEST DIRECTORIES THEY CHANGE BASED ON TESTS  #########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c031840",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"test2\" # you can change this according to your needs. to access that data.\n",
    "#current experiments are in test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934be3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "real = f\"{working_dir}/{experiment}/real_images\"\n",
    "#########################################################################################################\n",
    "\n",
    "directories = {\n",
    "    \"normalized\": f\"{working_dir}/{experiment}/normalized_images\",\n",
    "    \"cropped\": f\"{working_dir}/{experiment}/cropped_images\",\n",
    "    \"npy\": f\"{working_dir}/{experiment}/pre_processing/npy\",\n",
    "    \"originals\": f\"{working_dir}/{experiment}/pre_processing/originals\",\n",
    "    \"masks\": f\"{working_dir}/{experiment}/pre_processing/masks\",\n",
    "    \"test\": f\"{working_dir}/{experiment}/pre_processing/test\",\n",
    "    \"s\": f\"{working_dir}/{experiment}/S\",\n",
    "    \"crop_original\": f\"{working_dir}/{experiment}/pre_processing/crop_originals\",\n",
    "    \"crop_masks\": f\"{working_dir}/{experiment}/pre_processing/crop_masks\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8176393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c159d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################functions\n",
    "start_time = 0  # Define start_time in the global scope\n",
    "\n",
    "def starttime():\n",
    "    global start_time  # Use the global keyword to access the global start_time variable\n",
    "    start_time = time.time()\n",
    "    #hint: starttime() - To start timer.\n",
    "    \n",
    "def endtime():\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"Execution time: {execution_time:.2f} seconds\")\n",
    "    #hint: endtime() - To end timer\n",
    "\n",
    "def check(path):\n",
    "    # Create the directory if it does not exist\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    # Remove the directory and all its contents\n",
    "    shutil.rmtree(path)\n",
    "\n",
    "    # Create a new empty directory\n",
    "    os.mkdir(path)\n",
    "    #hint: check(path) - To recreate a particular path\n",
    "            \n",
    "def heavycrop(test):\n",
    "    starttime()\n",
    "    for z in tqdm(sorted(os.listdir(test))):\n",
    "        if z.endswith(\"tif\"):\n",
    "            # Read in the image\n",
    "            img = mh.imread(os.path.join(test, z))\n",
    "\n",
    "            # Calculate the number of crops in each dimension\n",
    "            height, width = img.shape[:2]\n",
    "            num_crops_y = height // 512\n",
    "            num_crops_x = width // 512\n",
    "\n",
    "            for i in range(num_crops_y):\n",
    "                for j in range(num_crops_x):\n",
    "                    # Crop the image\n",
    "                    start_y = i * 512\n",
    "                    start_x = j * 512\n",
    "                    img_cropped = img[start_y:start_y+512, start_x:start_x+512]\n",
    "\n",
    "                    # Create a new file name for the cropped image\n",
    "                    file_name, file_ext = os.path.splitext(z)\n",
    "                    new_file_name = f\"{file_name}_{i}_{j}{file_ext}\"\n",
    "\n",
    "                    # Save only if cropped image has shape (512, 512)\n",
    "                    if img_cropped.shape == (512, 512):\n",
    "                        mh.imsave(os.path.join(test, new_file_name), img_cropped)\n",
    "                    else:\n",
    "                        print(f\"Warning: Cropped image has unexpected shape {img_cropped.shape}\")\n",
    "                        \n",
    "            endtime()\n",
    "            # Remove original image file after cropping is done.\n",
    "            os.remove(os.path.join(test,z))\n",
    "            #hint: heavycrop(spath) - To heavy crop all images 512x512\n",
    "            \n",
    "def npyconversion(tif_dir, npy_path):\n",
    "    tif_files = [f for f in os.listdir(tif_dir) if f.endswith('.tif')]\n",
    "    data = []\n",
    "    for tif_file in tqdm(tif_files):\n",
    "        img = Image.open(os.path.join(tif_dir, tif_file))\n",
    "        data.append(np.array(img))\n",
    "    np.save(npy_path, data)\n",
    "    #hint: npyconversion(path , npy + '/filename.npy' ) -To create NPY files\n",
    "            \n",
    "def a2bcopy(path1, path2):\n",
    "    for z in tqdm(sorted(os.listdir(path1))):\n",
    "        if z.endswith(\"tif\"):\n",
    "            shutil.copy(os.path.join(path1, z), os.path.join(path2, z))\n",
    "            #hint: a2bcopy(sorce path, dest path) - To copy all images\n",
    "            \n",
    "def crop(test):\n",
    "    for z in tqdm(sorted(os.listdir(test))):\n",
    "        if (z.endswith(\"tif\")): # checking the file ends with tif\n",
    "            # Read in the image\n",
    "            img = mh.imread(os.path.join(test, z))\n",
    "            img_cropped = img[1000:2500, 2500:4500]\n",
    "            mh.imsave(os.path.join(test, z), img_cropped)\n",
    "            print(z)\n",
    "            #hint: crop(spath) - To crop all images\n",
    "    \n",
    "def a2brandom(src_dir, dst_dir, number):\n",
    "    # Get a list of all image files in the source directory\n",
    "    image_files = [f for f in tqdm(os.listdir(src_dir)) if f.endswith('.tif')]\n",
    "    # Randomly select 10 images from the list\n",
    "    selected_images = random.sample(image_files, number)\n",
    "    # Copy the selected images to the destination directory\n",
    "    for image in selected_images:\n",
    "        src_path = os.path.join(src_dir, image)\n",
    "        dst_path = os.path.join(dst_dir, image)\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "    # Print a message when done\n",
    "    print('Copied 10 random images to', dst_dir)\n",
    "    #hint: a2brandom(sorce path, dest path, random number) - To copy n random images\n",
    "    \n",
    "def count_files(dir_path):\n",
    "    if os.path.isdir(dir_path):\n",
    "        file_count = 0\n",
    "        for file_name in os.listdir(dir_path):\n",
    "            file_path = os.path.join(dir_path, file_name)\n",
    "            file_size_bytes = os.path.getsize(file_path)\n",
    "            file_size_mb = round(file_size_bytes / (1024 * 1024), 2)\n",
    "            #print(f'{file_name} - Size: {file_size_mb} MB')\n",
    "            file_count += 1\n",
    "        return file_count\n",
    "    else:\n",
    "        print(f\"{dir_path} is not a valid directory\")\n",
    "        return 0    \n",
    "        #hint: count_files(path) - To count number of files in that path\n",
    "    \n",
    "def norm(path):\n",
    "    for z in tqdm(sorted(os.listdir(path))):# added interactive progressbar to decrease the uncertanity and to increase curiosity :)\n",
    "        if (z.endswith(\"tif\")): # checking the file ends with tif \n",
    "            img = mh.imread(os.path.join(path, z))            \n",
    "            # Normalize the image\n",
    "            img = img.astype(np.float64)\n",
    "            img /= img.max()\n",
    "            img *= 255            \n",
    "            # Save the processed image back to the temporary directory\n",
    "            mh.imsave(os.path.join(path, z), img)\n",
    "            #hint: norm(path) - To normalize all the images in the path\n",
    "            \n",
    "def shape(raw):\n",
    "    for z in tqdm(sorted(os.listdir(raw))):\n",
    "        if (z.endswith(\"tif\")):\n",
    "            img = mh.imread(os.path.join(raw, z))\n",
    "            print (img.shape)\n",
    "            #hint: shape(path) _ To print shape of all the images in the path\n",
    "            \n",
    "def refresh(experiment: str, directories: dict):\n",
    "    for key in directories:\n",
    "        if os.path.exists(directories[key]):\n",
    "            shutil.rmtree(directories[key])\n",
    "        os.makedirs(directories[key])\n",
    "        #hint: refresh(\"experiment name\", directories) - to recreate all directories in that dict\n",
    "        \n",
    "def paths(directories):\n",
    "    for key, value in directories.items():\n",
    "        globals()[key] = value\n",
    "    return directories\n",
    "    #hint: paths(directories) - To call the directories outside the dictionary\n",
    "        \n",
    "def help():\n",
    "    functions = [value for key, value in globals().items() if inspect.isfunction(value)]\n",
    "    headers = [\"Function\", \"Hint\", \"Used for\"]\n",
    "    data = []\n",
    "    for func in functions:\n",
    "        source = inspect.getsource(func)\n",
    "        lines = source.split(\"\\n\")\n",
    "        hint_line = [line for line in lines if line.strip().startswith(\"#hint:\")]\n",
    "        if hint_line:\n",
    "            hint_parts = hint_line[0].split(\"#hint:\")[1].strip().split(\" - \")\n",
    "            hint_text = hint_parts[0]\n",
    "            usage_text = hint_parts[1] if len(hint_parts) > 1 else \"\"\n",
    "            data.append([f\"{func.__name__}()\", hint_text, usage_text])\n",
    "    print(tabulate(data, headers=headers))\n",
    "            \n",
    "            \n",
    "#def del(path):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b78aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths(directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a6951f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb48ad49",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## The below are manual functions to delete any particular directory and create it again. ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f20171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check(real)\n",
    "# check(normalized)\n",
    "# check(cropped)\n",
    "\n",
    "# check(crop_originals)\n",
    "# check(crop_masks)\n",
    "# check(npy)\n",
    "# check(originals)\n",
    "# check(masks)\n",
    "# check(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6ada03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MANUALLY CHECK THAT ALL FOLDERS ARE AVAILABLE AND EMPTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd8454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################      Getting some random data                ###############################\n",
    "raw = '/raid/mpsych/RISTERLAB/VSOverviewTileSet/Acquired/'\n",
    "raw1 = '/raid/mpsych/RISTERLAB/NINA_D1_MUTANTVSOverviewTileSet/Acquired'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adf72da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a2brandom(raw,data,800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d56986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a2brandom(raw1,data,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dbb241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_files(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d09a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a2bcopy(data,real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddafac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a2bcopy(data,normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11163738",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a2bcopy(data,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe2cb15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#a2bcopy(data,cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f64ef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_files(cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d4bf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############FINISHED COPYING FILES TO DIRECTORIES, NOW Normalization, cropping, segmentation ##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2787ada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6bcf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#norm(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6fe741",
   "metadata": {},
   "outputs": [],
   "source": [
    "#norm(cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a33a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5133ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crop(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efb7bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crop(cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed408902",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crop(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20a6b35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876663df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#heavycrop(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e788900",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!lspci | grep -i nvidia\n",
    "# TO check the graphic card availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67681a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_files(cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f23eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################    SEGMENTATION BEGIN    #########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2ac69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch\n",
    "#!pip install --upgrade torchvision\n",
    "#!pip install torchvision\n",
    "#!pip install scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db866d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f08f71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy\n",
    "from skimage import measure, filters\n",
    "import mahotas as mh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69039e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if numpy has an error, try the below command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da0212c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy==1.19.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2334c943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpustat #for gpu \n",
    "import torchvision\n",
    "print(torchvision.__version__)\n",
    "import scipy.ndimage\n",
    "import torch.nn.functional as F\n",
    "from scipy.ndimage import label\n",
    "#print(torchvision.__file__)\n",
    "#from torchvision.ops import connected_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1bdf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "def process_image(dir):\n",
    "    success = False  # Set default value for success\n",
    "    success_count=0 \n",
    "    for z in tqdm(sorted(os.listdir(dir))):\n",
    "        if (z.endswith(\"tif\")):            \n",
    "            img=mh.imread(os.path.join(dir,z)) \n",
    "            print (z)\n",
    "            #a =img.shape           \n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "            #img = torch.from_numpy(img).to('cuda')\n",
    "            #b = img.copy()\n",
    "            #b = torch.from_numpy(b)\n",
    "            # Move input data to GPU\n",
    "            #b = b.to('cuda')\n",
    "            \n",
    "            success = False            \n",
    "            for g in range(100, 0, -1):\n",
    "                # Initialize NVML\n",
    "                pynvml.nvmlInit()#####################################              GPU START\n",
    "                b = img.copy()\n",
    "                b = torch.from_numpy(b)\n",
    "                # Move input data to GPU\n",
    "                print (\"this iteration is with g value\",g)\n",
    "                b = b.to('cuda')\n",
    "                b.masked_fill_(b < g, 0)\n",
    "                # Label the regions in the filtered image\n",
    "                # Convert PyTorch tensor to numpy array\n",
    "                b_np = b.cpu().numpy()\n",
    "\n",
    "                # Find connected components in the image\n",
    "                labeled, number = scipy.ndimage.label(b_np)\n",
    "\n",
    "                # Convert labeled regions back to PyTorch tensor\n",
    "                labeled = torch.from_numpy(labeled).to(b.device)                \n",
    "                \n",
    "                number = labeled.max().item()\n",
    "                \n",
    "                \n",
    "                # filter based on labeled region size\n",
    "                sizes = torch.bincount(labeled.view(-1))\n",
    "                 # Remove the regions that are less than 1500\n",
    "                too_small = (sizes < 1500).nonzero(as_tuple=True)[0]\n",
    "                labeled_only_big = labeled.clone()\n",
    "                for i in too_small:\n",
    "                    labeled_only_big[labeled == i] = 0\n",
    "                \n",
    "                # Get the number of GPUs\n",
    "                device_count = pynvml.nvmlDeviceGetCount()########################             GPU\n",
    "                \n",
    "                # Create a binary mask from the filtered labeled regions\n",
    "                binary_mask = (labeled_only_big > 0).float()\n",
    "                number_1 = binary_mask.max().item()\n",
    "\n",
    "                # Close the regions in the binary mask\n",
    "                kernel_size=3\n",
    "                kernel=torch.ones((kernel_size,kernel_size),device=binary_mask.device)\n",
    "\n",
    "                binary_mask_closed=F.conv2d(binary_mask[None,None,...],kernel[None,None,...],padding=kernel_size//2)>0\n",
    "\n",
    "                #binary_mask_closed_filtered=F.gaussian_filter(binary_mask_closed.float(),sigma=3) \n",
    "                binary_mask_closed_filtered=(binary_mask_closed)\n",
    "                binary_mask_closed_filtered = binary_mask_closed_filtered.to(torch.float32)\n",
    "                \n",
    "                               \n",
    "                \n",
    "                \n",
    "                # Move tensor from GPU to CPU and convert to NumPy array\n",
    "                binary_mask_closed_filtered_np = binary_mask_closed_filtered.cpu().numpy()\n",
    "                ###edited               \n",
    "                \n",
    "                #changed this line check  ----ref for debugging\n",
    "                #labeled,number_final= label(binary_mask_closed_filtered.cpu())\n",
    "                labeled,number_final= label(binary_mask_closed_filtered_np)\n",
    "                \n",
    "\n",
    "                # Apply binary threshold to the image to segment the regions of interest                    \n",
    "                threshold=binary_mask_closed_filtered.flatten().kthvalue(int(binary_mask_closed_filtered.numel()*0.5))[0]                     \n",
    "                binary_image=binary_mask_closed_filtered>threshold   \n",
    "                \n",
    "                \n",
    "                 ###edited               \n",
    "                \n",
    "                #changed this line check  ----ref for debugging\n",
    "                # Move tensor from GPU to CPU and convert to NumPy array\n",
    "                binary_image_np = binary_image.cpu().numpy()\n",
    "                labeled,num_regions= label(binary_image_np)#, return_num=True)\n",
    "                \n",
    "                #closed this line and replaced with abovr --- ref for debugging\n",
    "                #labeled,num_regions= label(binary_image)#, return_num=True)\n",
    "\n",
    "                region_sizes=[(labeled==i+1).sum() for i in range(num_regions)]\n",
    "\n",
    "                min_region_size=5000\n",
    "\n",
    "                large_regions_counted=sum([size>min_region_size for size in region_sizes])\n",
    "\n",
    "\n",
    "                # Iterate over the region sizes and count the number of large regions\n",
    "\n",
    "                for region_size in region_sizes:\n",
    "                    if region_size > min_region_size:\n",
    "                        large_regions_counted += 1\n",
    "                        #print(large_regions_counted)\n",
    "                        \n",
    "                        \n",
    "                binary_image_np = binary_image.cpu().numpy() \n",
    "                binary_image_np = binary_image_np.reshape(binary_image_np.shape[2], binary_image_np.shape[3])\n",
    "                print (z)\n",
    "                \n",
    "                # Loop over each GPU and get its utilization rate\n",
    "                for i in range(device_count):\n",
    "                    handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n",
    "                    util = pynvml.nvmlDeviceGetUtilizationRates(handle)\n",
    "                    print(f\"GPU {i} - Utilization: {util.gpu}%\")\n",
    "                \n",
    "                # Shut down NVML\n",
    "                pynvml.nvmlShutdown()##############################################GPU\n",
    "               # plt.imshow(binary_image_np)\n",
    "                #plt.show()\n",
    "                #print (number_1,\" <=50 and number_1 >=25 \")\n",
    "                #print(large_regions, \">= 2\")\n",
    "                print (\"######################################################################\")\n",
    "\n",
    "                if number_1 <=150 and number_1 >=100:\n",
    "                    if large_regions_counted <=30:\n",
    "                        success=True\n",
    "                        print (\"######################################################################\")\n",
    "                        plt.imshow(binary_image_np)\n",
    "                        plt.show()\n",
    "                        #print(f'success: {success}')\n",
    "                        percent_success=(success_count/len(os.listdir(cropped)))*100\n",
    "                        print(f'percent_success: {percent_success}')\n",
    "                        #print(f'large_regions_counted: {large_regions_counted}')\n",
    "                        print ('number_1',number_1)\n",
    "                        print (\"######################################################################\")\n",
    "\n",
    "                        break       \n",
    "        \n",
    "\n",
    "        if success==True:\n",
    "            print (z)\n",
    "            plt.imshow(binary_image)\n",
    "            plt.show()\n",
    "            print (number_1,\" <=50 and number_1 >=25 \")\n",
    "            print(large_regions, \">= 2\")\n",
    "            print (\"######################################################################\")\n",
    "            #shutil.move(os.path.join(normalized,z),os.path.join(originals,z))                 \n",
    "            #shutil.move(os.path.join(cropped,z),os.path.join(masks,z))                 \n",
    "            #mh.imsave(os.path.join(masks,z),binary_image)                 \n",
    "            success_count+=1        \n",
    "            percent_success=(success_count/len(os.listdir(dir)))*100        \n",
    "            if percent_success>=50 and percent_success<100:\n",
    "                 print('50% Success')                \n",
    "            elif percent_success==100:\n",
    "                 print('100% Success')\n",
    "                    \n",
    "    # Move result back to CPU if needed\n",
    "    #result = result.to('cpu')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a56144",
   "metadata": {},
   "outputs": [],
   "source": [
    "cProfile.run('process_image(s)') #cprofile is for the bottle necks checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92ad513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7fc319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0c923f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624dd160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8711cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the files which got segemented well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62817614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# origi = int(count_files(masks))\n",
    "# croppi = int(count_files(real))\n",
    "# seg_well =(((origi)/(croppi))*100) \n",
    "# print (\"percentage = \",seg_well ,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551bb73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_files(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d03389",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (\"sucessfilly segemented\", origi,\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ca235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################   SEGMENTATION END   ################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef25870",
   "metadata": {},
   "outputs": [],
   "source": [
    "######copying data for heavycropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e56c9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a2bcopy(masks,crop_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116cc5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a2bcopy(originals,crop_originals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130da0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#heavycrop(crop_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcde6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#heavycrop(crop_originals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc8e57e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8884b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_files(crop_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46236cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_files(crop_originals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e558cbae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50391435",
   "metadata": {},
   "outputs": [],
   "source": [
    "#npyconversion(crop_originals, npy + '/original.npy' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba08853",
   "metadata": {},
   "outputs": [],
   "source": [
    "#npyconversion(crop_masks, npy + '/mask.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedb25dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#npyconversion(test, npy + '/test.npy' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ece825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_files(npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f37e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### run this command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344026c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy==1.19.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8357714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################  KERAS  #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb3db74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras-unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dde0f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import shutil\n",
    "import random\n",
    "import inspect\n",
    "#import imageio as im\n",
    "import numpy as np\n",
    "import mahotas as mh\n",
    "from PIL import Image\n",
    "from tabulate import tabulate\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "#from skimage import measure, filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62c299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original directory path and working directory path for images\n",
    "data = \"/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir/raw_files\"\n",
    "working_dir = \"/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir\"\n",
    "######################################################################################################\n",
    "experiment = \"test2\" \n",
    "######################################################################################################\n",
    "real = f\"{working_dir}/{experiment}/real_images\"\n",
    "#########################################################################################################\n",
    "\n",
    "directories = {\n",
    "    \"normalized\": f\"{working_dir}/{experiment}/normalized_images\",\n",
    "    \"cropped\": f\"{working_dir}/{experiment}/cropped_images\",\n",
    "    \"npy\": f\"{working_dir}/{experiment}/pre_processing/npy\",\n",
    "    \"originals\": f\"{working_dir}/{experiment}/pre_processing/originals\",\n",
    "    \"masks\": f\"{working_dir}/{experiment}/pre_processing/masks\",\n",
    "    \"test\": f\"{working_dir}/{experiment}/pre_processing/test\",\n",
    "    \"s\": f\"{working_dir}/{experiment}/S\",\n",
    "    \"crop_original\": f\"{working_dir}/{experiment}/pre_processing/crop_originals\",\n",
    "    \"crop_masks\": f\"{working_dir}/{experiment}/pre_processing/crop_masks\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451c8f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start.keras(npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a691756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras_unet.models import custom_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac7b484",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir/raw_files\"\n",
    "working_dir = \"/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir\"\n",
    "######################################################################################################\n",
    "experiment = \"test2\" \n",
    "######################################################################################################\n",
    "real = f\"{working_dir}/{experiment}/real_images\"\n",
    "npy= f\"{working_dir}/{experiment}/pre_processing/npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712fabc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_file = os.path.join(npy, 'original.npy')\n",
    "labels_file = os.path.join(npy, 'mask.npy')\n",
    "#test_files = os.path.join(npy, 'test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c666dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load(images_file)\n",
    "labels = np.load(labels_file)\n",
    "#test = np.load(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68111694",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfb1855",
   "metadata": {},
   "outputs": [],
   "source": [
    " # full dataset does not have the last channel\n",
    "images = images.reshape(images.shape[0],images.shape[1],images.shape[2],1)\n",
    "labels = labels.reshape(labels.shape[0],labels.shape[1],labels.shape[2],1)\n",
    "#test = test.reshape(test.shape[0],test.shape[1],test.shape[2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297420b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c495ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.random.permutation(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2283d8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images[p]\n",
    "labels = labels[p]\n",
    "#test = test[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f342762",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc746342",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.astype(np.float64)\n",
    "for i in range(images.shape[0]):\n",
    "    images[i] = (images[i] - images[i].min()) / (images[i].max() - images[i].min()) # normalize individually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d25d41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fb719d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a79e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = images[0:1200]\n",
    "y_train = labels[0:1200]\n",
    "X_val = images[1201:1700]\n",
    "y_val = labels[1201:1700]\n",
    "X_test = images[1701:1812]\n",
    "y_test = labels[1701:1812]\n",
    "\n",
    "#X_test = test[80:]\n",
    "#y_test = test[80:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d655d20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = custom_unet(\n",
    "    input_shape=(512, 512, 1),\n",
    "    use_batch_norm=False,\n",
    "    num_classes=1,\n",
    "    filters=32,\n",
    "    dropout=0.5,\n",
    "    output_activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509b5258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.optimizers\n",
    "from keras_unet.metrics import iou, iou_thresholded\n",
    "from keras_unet.losses import jaccard_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c25b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6136c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizer_v1.Adam(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93d09ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'Adam',    \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=[iou, iou_thresholded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004d0ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### batch size 50 , epochs =1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8242b17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(batch,epochs):\n",
    "    print (\"training and prediction for\",\"batch size:  \",batch, \"epochs:  \" ,epochs)\n",
    "    history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    batch, \n",
    "                    epochs=epochs,\n",
    "                    validation_data=(X_val, y_val), \n",
    "                    verbose=1)\n",
    "def plot(): \n",
    "    from keras_unet.utils import plot_segm_history\n",
    "    plot_segm_history(history)    \n",
    "    y_pred = model.predict(X_test)    \n",
    "    from keras_unet.utils import plot_imgs\n",
    "    plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred, nm_img_to_plot=10)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebc5424",
   "metadata": {},
   "outputs": [],
   "source": [
    "training(60,40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71842df5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3b6ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16356b42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f01e27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a958b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394d4f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634bf9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3719c892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5317721f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c167bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb95763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caaeeb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d1ae85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abbfb9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b915248e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d75e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2b098e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    50, \n",
    "                    epochs=1000,\n",
    "                    validation_data=(X_val, y_val), \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847076ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_unet.utils import plot_segm_history\n",
    "\n",
    "plot_segm_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89f181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1d5c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_unet.utils import plot_imgs\n",
    "\n",
    "plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred, nm_img_to_plot=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5afdbe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0faf44",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training(60,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cf401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc85852",
   "metadata": {},
   "outputs": [],
   "source": [
    "training(65,65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303484ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "overlay(directories['originals'],directories['masks'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08140724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e467069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b64647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847f24be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0a0dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c318f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee725e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "def overlay(original_dir, mask_dir, n):\n",
    "    original_images = os.listdir(original_dir)\n",
    "    mask_images = os.listdir(mask_dir)\n",
    "\n",
    "    for i in range(n):\n",
    "        original_image = random.choice(original_images)\n",
    "        mask_image = original_image.replace('.png', '_mask.png')\n",
    "        if mask_image in mask_images:\n",
    "            img = Image.open(os.path.join(original_dir, original_image))\n",
    "            mask = Image.open(os.path.join(mask_dir, mask_image))\n",
    "            img.paste(mask, (0, 0), mask)\n",
    "            img.show()\n",
    "            #hint: # overlay_masks('original', 'masks', 3) - To plot overlay wiht masks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91cce3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras-unet\n",
    "\n",
    "# import keras\n",
    "# from keras_unet.models import custom_unet\n",
    "\n",
    "# images_file = os.path.join(npy_files, 'original.npy')\n",
    "# labels_file = os.path.join(npy_files, 'mask.npy')\n",
    "\n",
    "# images = np.load(images_file)\n",
    "# labels = np.load(labels_file)\n",
    "\n",
    "# images.shape\n",
    "\n",
    "# # full dataset does not have the last channel\n",
    "# images = images.reshape(images.shape[0],images.shape[1],images.shape[2],1)\n",
    "# labels = labels.reshape(labels.shape[0],labels.shape[1],labels.shape[2],1)\n",
    "\n",
    "# images.shape\n",
    "\n",
    "# p = np.random.permutation(len(images))\n",
    "\n",
    "# images = images[p]\n",
    "# labels = labels[p]\n",
    "\n",
    "# labels = labels.astype(np.float64)\n",
    "\n",
    "# images = images.astype(np.float64)\n",
    "\n",
    "# for i in range(images.shape[0]):\n",
    "#     images[i] = (images[i] - images[i].min()) / (images[i].max() - images[i].min()) # normalize individually\n",
    "\n",
    "\n",
    "# images.shape\n",
    "\n",
    "# X_train = images[0:50]\n",
    "# y_train = labels[0:50]\n",
    "# X_val = images[10:20]\n",
    "# y_val = labels[10:20]\n",
    "# X_test = images[0:]\n",
    "# y_test = labels[0:]\n",
    "\n",
    "# model = custom_unet(\n",
    "#     input_shape=(512, 512, 1),\n",
    "#     use_batch_norm=False,\n",
    "#     num_classes=1,\n",
    "#     filters=32,\n",
    "#     dropout=0.5,\n",
    "#     output_activation='sigmoid')\n",
    "\n",
    "# import keras.optimizers\n",
    "# from keras_unet.metrics import iou, iou_thresholded\n",
    "# from keras_unet.losses import jaccard_distance\n",
    "\n",
    "\n",
    "\n",
    "# opt = keras.optimizer_v1.Adam(lr=0.01)\n",
    "\n",
    "# model.compile(optimizer = 'Adam',    \n",
    "#               loss='binary_crossentropy', \n",
    "#               metrics=[iou, iou_thresholded])\n",
    "\n",
    "# history = model.fit(X_train, \n",
    "#                     y_train, \n",
    "#                     50, \n",
    "#                     epochs=500,\n",
    "#                     validation_data=(X_val, y_val), \n",
    "#                     verbose=1)\n",
    "\n",
    "# from keras_unet.utils import plot_segm_history\n",
    "\n",
    "# plot_segm_history(history)\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# from keras_unet.utils import plot_imgs\n",
    "\n",
    "# plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred, nm_img_to_plot=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef9bf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My next idea in the pipe line is to compare same images on different iterations and come to conclusion.\n",
    "# To decide what batch size and epochs gives the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73205ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
