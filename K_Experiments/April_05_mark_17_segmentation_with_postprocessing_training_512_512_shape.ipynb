{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb3db74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras-unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150a1f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import shutil\n",
    "import random\n",
    "import inspect\n",
    "#import imageio as im\n",
    "import numpy as np\n",
    "import mahotas as mh\n",
    "from PIL import Image\n",
    "from tabulate import tabulate\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "#from skimage import measure, filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef84d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original directory path and working directory path for images\n",
    "data = \"/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir/raw_files\"\n",
    "working_dir = \"/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir\"\n",
    "######################################################################################################\n",
    "experiment = \"test3\" \n",
    "######################################################################################################\n",
    "real = f\"{working_dir}/{experiment}/real_images\"\n",
    "#########################################################################################################\n",
    "\n",
    "directories = {\n",
    "    \"normalized\": f\"{working_dir}/{experiment}/normalized_images\",\n",
    "    \"cropped\": f\"{working_dir}/{experiment}/cropped_images\",\n",
    "    \"npy\": f\"{working_dir}/{experiment}/pre_processing/npy\",\n",
    "    \"originals\": f\"{working_dir}/{experiment}/pre_processing/originals\",\n",
    "    \"masks\": f\"{working_dir}/{experiment}/pre_processing/masks\",\n",
    "    \"test\": f\"{working_dir}/{experiment}/pre_processing/test\",\n",
    "    \"s\": f\"{working_dir}/{experiment}/S\",\n",
    "    \"crop_original\": f\"{working_dir}/{experiment}/pre_processing/crop_originals\",\n",
    "    \"crop_masks\": f\"{working_dir}/{experiment}/pre_processing/crop_masks\",\n",
    "    \"op\": f\"{working_dir}/{experiment}/post_processing/original_prediction\",\n",
    "    \"pp\": f\"{working_dir}/{experiment}/post_processing/processed_prediction\"\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66832281",
   "metadata": {},
   "outputs": [],
   "source": [
    "npy = f\"{working_dir}/{experiment}/pre_processing/npy1\"\n",
    "machine = f\"{working_dir}/{experiment}/pre_processing/machine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a691756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras_unet.models import custom_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd7fedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagedata = np.load(os.path.join(npy, 'original.npz'))\n",
    "labeldata = np.load(os.path.join(npy, 'mask.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002d1fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_file = imagedata['data']\n",
    "images_name = imagedata['names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9493970",
   "metadata": {},
   "outputs": [],
   "source": [
    "len (images_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712fabc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_file = labeldata['data']\n",
    "labels_name = labeldata['names']\n",
    "\n",
    "\n",
    "#labels_file = os.path.join(npy, 'mask.npy')\n",
    "#test_files = os.path.join(npy, 'test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c666dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images_file\n",
    "labels = labels_file\n",
    "#test = np.load(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68111694",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a2618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfb1855",
   "metadata": {},
   "outputs": [],
   "source": [
    " # full dataset does not have the last channel\n",
    "images = images.reshape(images.shape[0],images.shape[1],images.shape[2],1)\n",
    "labels = labels.reshape(labels.shape[0],labels.shape[1],labels.shape[2],1)\n",
    "#test = test.reshape(test.shape[0],test.shape[1],test.shape[2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297420b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71e7668",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c495ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.random.permutation(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2283d8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images[p]\n",
    "labels = labels[p]\n",
    "#test = test[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f342762",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc746342",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.astype(np.float64)\n",
    "for i in range(images.shape[0]):\n",
    "    images[i] = (images[i] - images[i].min()) / (images[i].max() - images[i].min()) # normalize individually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a1fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate the indices for the splits\n",
    "# num_images = len(images)\n",
    "# num_labels = len(labels)\n",
    "# train_x = int(num_images * 0.6)\n",
    "# train_y = int(num_labels * 0.6)\n",
    "# val_x = int(num_images * 0.85)\n",
    "# val_y = int(num_labels * 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a79e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = images[:train_x]\n",
    "# y_train = labels[:train_y]\n",
    "# X_val = images[train_x:val_x]\n",
    "# y_val = labels[train_y:val_y]\n",
    "# X_test = images[val_x:]\n",
    "# y_test = labels[val_y:]\n",
    "\n",
    "#X_test = test[80:]\n",
    "#y_test = test[80:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4121c81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = images[0:1200]\n",
    "y_train = labels[0:1200]\n",
    "X_val = images[1201:1700]\n",
    "y_val = labels[1201:1700]\n",
    "X_test = images[0:1812]\n",
    "y_test = labels[0:1812]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a1ba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554d2f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomimage(abc):\n",
    "    jk = 1187\n",
    "    binary_mask = y_train[jk]#.squeeze()\n",
    "    # Plot the binary mask\n",
    "    plt.imshow(binary_mask, cmap='gray')\n",
    "    plt.show()\n",
    "    labeled, number = mh.label(binary_mask)\n",
    "    sizes = mh.labeled.labeled_size(labeled)\n",
    "    print(sizes)\n",
    "    a =sizes.max()\n",
    "    print('size-max',a)\n",
    "    b =sizes.min()\n",
    "    print('size-min',b)\n",
    "    c = binary_mask.shape\n",
    "    print('shape',c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fa11e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomimage(897)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0529177",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################   LOADING MODEL   ######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa06110",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizer_v1.Adam(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326d0e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from keras.metrics import MeanIoU\n",
    "\n",
    "n_classes = 2 # number of classes in your segmentation masks\n",
    "IoU = MeanIoU(num_classes=n_classes)\n",
    "\n",
    "model = Sequential()\n",
    "# Encoder\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(512, 512,1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "\n",
    "# Decoder\n",
    "model.add(Conv2DTranspose(128, (3, 3), strides=(2, 2), activation='relu', padding='same'))\n",
    "model.add(Conv2DTranspose(64, (3, 3), strides=(2, 2), activation='relu', padding='same'))\n",
    "model.add(Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[IoU])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed18a823",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### IMPORTS #############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b1d9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_unet.utils import plot_segm_history, plot_imgs\n",
    "from skimage import measure\n",
    "\n",
    "import skimage.filters as filters\n",
    "import skimage.measure as measure\n",
    "from sklearn.metrics import classification_report\n",
    "import keras.optimizers\n",
    "from keras_unet.metrics import iou, iou_thresholded\n",
    "from keras_unet.losses import jaccard_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79d299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################   FUNCTIONS ######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c9b072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels(binary_mask):\n",
    "    # Calculate number_1\n",
    "    labeled, num = mh.label(binary_mask)\n",
    "    print(\"Number_1:\", num)\n",
    "\n",
    "    # Calculate region sizes\n",
    "    region_sizes = measure.regionprops(labeled, intensity_image=binary_mask)\n",
    "    sizes = [region.area for region in region_sizes]\n",
    "\n",
    "    # Find min_region_size\n",
    "    sizes.sort()\n",
    "    large_region_start_index = next((i for i in range(1,len(sizes)) if sizes[i] - sizes[i-1] < numbi), len(sizes))\n",
    "    #large_region_start_index = next((i for i in range(1,len(sizes)) if sizes[i] - sizes[i-1] > 100), len(sizes))\n",
    "    min_region_size = (sizes[large_region_start_index-1] + sizes[large_region_start_index]) // 2\n",
    "    print(\"Min_region_size:\", min_region_size)\n",
    "    #print ('sizes:',sizes)\n",
    "    a = len(sizes)\n",
    "    print ('length of sizes =',a)\n",
    "\n",
    "    # Calculate large_regions\n",
    "    num_large_regions = 0\n",
    "    for region in region_sizes:\n",
    "        if region.area > min_region_size:\n",
    "            num_large_regions += 1\n",
    "    print(\"Large_regions:\", num_large_regions)\n",
    "\n",
    "    # Calculate threshold\n",
    "    thresh = filters.threshold_otsu(binary_mask)\n",
    "    #print(labels_name[jk])\n",
    "    print(\"Threshold:\", thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a73b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pros(binary_mask):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from io import StringIO\n",
    "    import sys\n",
    "    # ...\n",
    "\n",
    "    fig, axs = plt.subplots(1, 5, figsize=(15, 5))\n",
    "\n",
    "    # Operation 1\n",
    "    labeled, number = mh.label(binary_mask)\n",
    "    sizes = mh.labeled.labeled_size(labeled)\n",
    "    numbi = int(np.average(sizes))\n",
    "    large_region_start_index = next((i for i in range(1,len(sizes)) if sizes[i] - sizes[i-1] < numbi), len(sizes))\n",
    "    min_region_size = (sizes[large_region_start_index-1] + sizes[large_region_start_index]) // 2\n",
    "    too_small = np.where(sizes < min_region_size)\n",
    "    labeled_only_big = mh.labeled.remove_regions(labeled, too_small)\n",
    "    axs[0].imshow(labeled)\n",
    "    #axs[0].imshow(labeled_only_big)\n",
    "    axs[0].set_title('Operation 1')\n",
    "\n",
    "    # Capture the output of the labels function\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = mystdout = StringIO()\n",
    "\n",
    "    labels(labeled_only_big)\n",
    "\n",
    "    # Restore stdout\n",
    "    sys.stdout = old_stdout\n",
    "\n",
    "    # Display the captured output as text below the subplot\n",
    "    axs[0].text(0.5, -0.1, mystdout.getvalue(), ha='center', va='top', transform=axs[0].transAxes)\n",
    "\n",
    "    # Operation 2\n",
    "    binary_mask = labeled_only_big.copy()\n",
    "    binary_mask[binary_mask > 0] = 1\n",
    "\n",
    "    axs[1].imshow(binary_mask)\n",
    "    axs[1].set_title('Operation 2')\n",
    "\n",
    "    # Capture the output of the labels function\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = mystdout = StringIO()\n",
    "\n",
    "    labels(binary_mask)\n",
    "\n",
    "    # Restore stdout\n",
    "    sys.stdout = old_stdout\n",
    "\n",
    "    # Display the captured output as text below the subplot\n",
    "    axs[1].text(0.5, -0.1, mystdout.getvalue(), ha='center', va='top', transform=axs[1].transAxes)\n",
    "\n",
    "    # Operation 3\n",
    "    binary_mask_closed = mh.gaussian_filter(binary_mask, sigma=5)\n",
    "\n",
    "    axs[2].imshow(binary_mask_closed)\n",
    "    axs[2].set_title('Operation 3')\n",
    "\n",
    "    # Capture the output of the labels function\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = mystdout = StringIO()\n",
    "\n",
    "    labels(binary_mask_closed)\n",
    "\n",
    "    # Restore stdout\n",
    "    sys.stdout = old_stdout\n",
    "\n",
    "    # Display the captured output as text below the subplot\n",
    "    axs[2].text(0.5, -0.1, mystdout.getvalue(), ha='center', va='top', transform=axs[2].transAxes)\n",
    "\n",
    "    # Operation 4\n",
    "    binary_mask= binary_mask.reshape(binary_mask.shape[0],binary_mask.shape[1])\n",
    "    binary_mask_open = mh.morph.close_holes(binary_mask)\n",
    "\n",
    "    #axs[3].imshow(binary_mask_open)\n",
    "    axs[3].set_title('Operation 4')\n",
    "\n",
    "    # Capture the output of the labels function\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = mystdout = StringIO()\n",
    "\n",
    "    labels(binary_mask_open)\n",
    "\n",
    "    # Restore stdout\n",
    "    sys.stdout = old_stdout\n",
    "\n",
    "    # Display the captured output as text below the subplot\n",
    "    axs[3].text(0.5, -0.1, mystdout.getvalue(), ha='center', va='top', transform=axs[3].transAxes)\n",
    "\n",
    "    # Operation 5\n",
    "    for i in range(3):\n",
    "        binary_mask_dialate = mh.morph.dilate(binary_mask_open)\n",
    "\n",
    "    axs[4].imshow(binary_mask_dialate)\n",
    "    axs[4].set_title('Operation 5')\n",
    "\n",
    "    # Capture the output of the labels function\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = mystdout = StringIO()\n",
    "\n",
    "    labels(binary_mask_dialate)\n",
    "\n",
    "    # Restore stdout\n",
    "    sys.stdout = old_stdout\n",
    "\n",
    "    # Display the captured output as text below the subplot\n",
    "    axs[4].text(0.5, -0.1, mystdout.getvalue(), ha='center', va='top', transform=axs[4].transAxes)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23b6a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readpaths(directories):\n",
    "    for key, path in directories.items():\n",
    "        globals()[key] = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8222e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "readpaths(directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a58c500",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610b6a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "jk = 1187"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44310122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomimage(abc):\n",
    "    jk = 1187\n",
    "    #binary_mask = y_train[jk].squeeze()\n",
    "    # Plot the binary mask\n",
    "    plt.imshow(binary_mask, cmap='gray')\n",
    "    plt.show()\n",
    "    labeled, number = mh.label(binary_mask)\n",
    "    sizes = mh.labeled.labeled_size(labeled)\n",
    "    print(sizes)\n",
    "    a =sizes.max()\n",
    "    print('size-max',a)\n",
    "    b =sizes.min()\n",
    "    print('size-min',b)\n",
    "    c = binary_mask.shape\n",
    "    print('shape',c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510c5e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "jk = 1087\n",
    "#binary_mask = y_train[jk].squeeze()\n",
    "# Plot the binary mask\n",
    "plt.imshow(binary_mask, cmap='gray')\n",
    "plt.show()\n",
    "labeled, number = mh.label(binary_mask)\n",
    "sizes = mh.labeled.labeled_size(labeled)\n",
    "print(sizes)\n",
    "a =sizes.max()\n",
    "print('size-max',a)\n",
    "b =sizes.min()\n",
    "print('size-min',b)\n",
    "c = binary_mask.shape\n",
    "print('shape',c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f0e7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled, number = mh.label(binary_mask)\n",
    "sizes = mh.labeled.labeled_size(labeled)\n",
    "# large_region_start_index = next((i for i in range(1,len(sizes)) if sizes[i] - sizes[i-1]), len(sizes))\n",
    "# min_region_size = (sizes[large_region_start_index-1] + sizes[large_region_start_index]) // 2\n",
    "# too_small = np.where(sizes < min_region_size)\n",
    "# labeled_only_big = mh.labeled.remove_regions(labeled, too_small)\n",
    "# axs[0].imshow(labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f03aa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a423cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5981457",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f80c4c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.average(sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f962a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c29855",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_index = np.argmax(sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd73546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove maximum value\n",
    "sizes = np.delete(sizes, max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530b1f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0c0397",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0539bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = int(np.average(sizes))\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8323976",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d13c5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbi = int(np.average(sizes))\n",
    "large_region_start_index = next((i for i in range(1, len(sizes)) if (sizes[i] - sizes[i-1]) < numbi), len(sizes))\n",
    "min_region_size = (sizes[large_region_start_index-1] + sizes[large_region_start_index]) // 2\n",
    "print (min_region_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2109c1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(binary_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7361ab09",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled, number = mh.label(binary_mask)\n",
    "\n",
    "plt.imshow(labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ac45d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_mask = labeled.copy()\n",
    "binary_mask[binary_mask > 0] = 1\n",
    "   \n",
    "plt.imshow(binary_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3baea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_sizes = measure.regionprops(binary_mask, intensity_image=binary_mask)\n",
    "print(region_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92af0eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labeled, number = mh.label(binary_mask)\n",
    "sizes = mh.labeled.labeled_size(labeled)\n",
    "#sizes = np.array([region.area for region in region_sizes], dtype=np.int64)\n",
    "numbi = int(np.average(sizes))\n",
    "#print(sizes)\n",
    "\n",
    "# large_region_start_index = next((i for i in range(1,len(sizes)) if sizes[i] - sizes[i-1] < numbi), len(sizes))\n",
    "# print(large_region_start_index)\n",
    "# min_region_size = (sizes[large_region_start_index-1] + sizes[large_region_start_index]) // 2\n",
    "# print(min_region_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80947f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3afc80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e439cdf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import mahotas as mh\n",
    "from skimage import measure, filters\n",
    "import matplotlib.pyplot as plt\n",
    "jk = 87\n",
    "# Select a single binary mask from y_train\n",
    "binary_mask = y_train[jk].squeeze()\n",
    "\n",
    "# Plot the binary mask\n",
    "plt.imshow(binary_mask, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# Calculate number_1\n",
    "labeled, num = mh.label(binary_mask)\n",
    "print(\"Number_1:\", num)\n",
    "\n",
    "# Calculate region sizes\n",
    "region_sizes = measure.regionprops(labeled, intensity_image=binary_mask)\n",
    "sizes = [region.area for region in region_sizes]\n",
    "\n",
    "# Find min_region_size\n",
    "sizes.sort()\n",
    "large_region_start_index = next((i for i in range(1,len(sizes)) if sizes[i] - sizes[i-1] > 100), len(sizes))\n",
    "min_region_size = (sizes[large_region_start_index-1] + sizes[large_region_start_index]) // 2\n",
    "print(\"Min_region_size:\", min_region_size)\n",
    "\n",
    "# Calculate large_regions\n",
    "num_large_regions = 0\n",
    "for region in region_sizes:\n",
    "    if region.area > min_region_size:\n",
    "        num_large_regions += 1\n",
    "print(\"Large_regions:\", num_large_regions)\n",
    "\n",
    "# Calculate threshold\n",
    "thresh = filters.threshold_otsu(binary_mask)\n",
    "print(labels_name[jk])\n",
    "print(\"Threshold:\", thresh)\n",
    "print()\n",
    "print(labels_name[jk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeee9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sizes)\n",
    "len(sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94255b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled, number = mh.label(binary_mask)\n",
    "sizes = mh.labeled.labeled_size(labeled)\n",
    "print (sizes)\n",
    "len(sizes)\n",
    "too_small = np.where(sizes < min_region_size)\n",
    "labeled_only_big = mh.labeled.remove_regions(labeled, too_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870e2a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05389f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_mask_closed = mh.gaussian_filter(binary_mask, sigma=5)\n",
    "\n",
    "plt.imshow(binary_mask_closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8849c389",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_mask_open=mh.morph.close_holes(binary_mask)\n",
    "plt.imshow(binary_mask_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f654d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    binary_mask_open = mh.morph.dilate(binary_mask_open)\n",
    "    plt.imshow(binary_mask_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730116f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"test3\" \n",
    "working_dir = \"/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir\"\n",
    "pp =f\"{working_dir}/{experiment}/post_processing/processed_prediction\"\n",
    "op = f\"{working_dir}/{experiment}/post_processing/original_prediction\"\n",
    "crop_original =  f\"{working_dir}/{experiment}/pre_processing/crop_originals\"\n",
    "crop_masks = f\"{working_dir}/{experiment}/pre_processing/crop_masks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c18661c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_unet.utils import plot_segm_history, plot_imgs\n",
    "from skimage import measure\n",
    "\n",
    "import skimage.filters as filters\n",
    "import skimage.measure as measure\n",
    "from sklearn.metrics import classification_report\n",
    "import keras.optimizers\n",
    "from keras_unet.metrics import iou, iou_thresholded\n",
    "from keras_unet.losses import jaccard_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f9ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mahotas as mh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363f42ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ede4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eb55ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    batch_size=60,\n",
    "                    epochs=150,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stopping])\n",
    "# Make predictions and apply thresholding\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Apply contrast stretching to the predicted images\n",
    "new_min_value = 0\n",
    "new_max_value = 255\n",
    "\n",
    "for i in range(y_pred.shape[0]): # for i in range(y_pred.shape[0])\n",
    "    z = images_name[i]\n",
    "    binary_mask = y_pred[i]\n",
    "    binary_mask.shape    \n",
    "    print(binary_mask.shape)\n",
    "    \n",
    "    # Apply Otsu's thresholding to binary mask\n",
    "    thresh = 0.25\n",
    "    #thresh = threshold_otsu(binary_mask)\n",
    "    binary_mask_thresh = binary_mask > thresh\n",
    "    \n",
    "    sizes_b = mh.labeled.labeled_size(binary_mask_thresh)\n",
    "    \n",
    "    \n",
    "    print(z)\n",
    "    plt.imshow(binary_mask_thresh)\n",
    "    plt.show()\n",
    "    print(binary_mask_thresh.shape)\n",
    "    print(\"Sizes for image a\", sizes_b)\n",
    "    \n",
    "    # Convert binary mask to uint8 format\n",
    "    binary_mask_uint8 = (binary_mask * 255).astype('uint8')\n",
    "    \n",
    "#     labeled12, number = mh.label(binary_mask_uint8)\n",
    "#     sizes_l12 = mh.labeled.labeled_size(labeled12)\n",
    "#     print(\"Sizes for image\", sizes_l12)\n",
    "    \n",
    "    # Remove any singleto0n dimensions\n",
    "    binary_mask_uint8 = np.squeeze(binary_mask_uint8)\n",
    "#     labeled12, number = mh.label(binary_mask_uint82)\n",
    "#     sizes_l13 = mh.labeled.labeled_size(labeled12)\n",
    "#     print(\"Sizes for image binary_mask_uint82\", sizes_l13)\n",
    "\n",
    "    # Select only the first channel if necessary\n",
    "    if binary_mask_uint8.ndim == 3 and binary_mask_uint8.shape[2] not in [1, 3, 4]:\n",
    "        binary_mask_uint8 = binary_mask_uint8[..., 0]\n",
    "        \n",
    "#     labeled1, number = mh.label(binary_mask_uint8)\n",
    "#     sizes_l1 = mh.labeled.labeled_size(labeled1)\n",
    "#     print(\"Sizes for image binary_mask_uint8\", sizes_l1)\n",
    "    \n",
    "    \n",
    "    plt.imshow(binary_mask_uint8)\n",
    "    plt.show()\n",
    "    print ('###############')\n",
    "    # Create Image object from binary mask\n",
    "    binary_mask_imag = Image.fromarray(binary_mask_uint8)\n",
    "    # Save binary mask image\n",
    "    binary_mask_imag.save(f'{op}/{z}')\n",
    "    print(f'saved:{op}/{z}')\n",
    "#     save_path = os.path.join(op, z)\n",
    "#     print(\"Saving image to:\", save_path)    \n",
    "#     mh.imsave(save_path, binary_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84c419b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b74a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb795cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "from skimage.filters import threshold_otsu\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# # Create an instance of the ImageDataGenerator class\n",
    "# datagen = ImageDataGenerator(\n",
    "#     rotation_range=10, # randomly rotate images up to 10 degrees\n",
    "#     width_shift_range=0.1, # randomly shift images horizontally by up to 10%\n",
    "#     height_shift_range=0.1, # randomly shift images vertically by up to 10%\n",
    "#     horizontal_flip=True, # randomly flip images horizontally\n",
    "#     zoom_range=0.1 # randomly zoom in/out on images by up to 10%\n",
    "# )\n",
    "\n",
    "# # Fit the data generator on your training data\n",
    "# datagen.fit(X_train)\n",
    "\n",
    "# # Early stopping\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "# history = model.fit(\n",
    "#                     datagen.flow(X_train, y_train, batch_size=60),                    \n",
    "#                     epochs=700,\n",
    "#                     validation_data=(X_val, y_val),\n",
    "#                     callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "# # Save the trained weights to a file\n",
    "# model.save_weights('new_model1.h5')\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    batch_size=60,\n",
    "                    epochs=700,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stopping])\n",
    "# # Save the trained weights to a file\n",
    "model.save_weights('new_model1.h5')\n",
    "# Make predictions and apply thresholding\n",
    "y_pred = model.predict(X_test)\n",
    "for i in range(5):\n",
    "    z = images_name[i]\n",
    "    binary_mask = y_pred[i]\n",
    "    plt.imshow(binary_mask)\n",
    "    plt.show()\n",
    "    \n",
    "history.history.keys()\n",
    "metrics = list(history.history.keys())\n",
    "plot_segm_history(history, metrics=metrics)   \n",
    "plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred, nm_img_to_plot=5)\n",
    "#     #thresh = threshold_otsu(binary_mask)\n",
    "#     binary_mask_thresh = binary_mask > thresh    \n",
    "#     sizes_b = mh.labeled.labeled_size(binary_mask_thresh)\n",
    "#     binary_mask_uint8 = (binary_mask * 255).astype('uint8')\n",
    "#     binary_mask_uint8 = np.squeeze(binary_mask_uint8)\n",
    "#     # Select only the first channel if necessary\n",
    "#     if binary_mask_uint8.ndim == 3 and binary_mask_uint8.shape[2] not in [1, 3, 4]:\n",
    "#         binary_mask_uint8 = binary_mask_uint8[..., 0]\n",
    "#     # Create Image object from binary mask\n",
    "#     binary_mask_imag = Image.fromarray(binary_mask_uint8)\n",
    "#     # Save binary mask image\n",
    "# #     binary_mask_imag.save(f'{op}/{z}')\n",
    "# #     print(f'saved:{op}/{z}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b040f5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    n_classes = 2 # number of classes in your segmentation masks\n",
    "    IoU = MeanIoU(num_classes=n_classes)\n",
    "    model = Sequential()\n",
    "    # Encoder\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(512, 512,1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    # Decoder\n",
    "    model.add(Conv2DTranspose(128, (3, 3), strides=(2, 2), activation='relu', padding='same'))\n",
    "    model.add(Conv2DTranspose(64, (3, 3), strides=(2, 2), activation='relu', padding='same'))\n",
    "    model.add(Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same'))\n",
    "#         model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[IoU])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c717d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wtrain(number):\n",
    "    import cv2\n",
    "    from PIL import Image\n",
    "    from skimage.filters import threshold_otsu\n",
    "    from keras.preprocessing.image import ImageDataGenerator\n",
    "    al = 1\n",
    "    for k in range(number):\n",
    "        # create a new model with the same architecture as the original model\n",
    "        new_model = create_model()\n",
    "        path = '/raid/mpsych/RISTERLAB/kiran/flyem/K_Experiments/models'\n",
    "        # load the previously saved weights into the new model\n",
    "        new_model.load_weights(f'{path}/new_model{al}.h5')\n",
    "        print (f'loaded model : new_model{al}.h5')\n",
    "        # compile the new model\n",
    "        IoU = MeanIoU(num_classes=2)\n",
    "        \n",
    "        # compile the new model\n",
    "        new_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[IoU])\n",
    "        # Early stopping\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "        history = new_model.fit(X_train,\n",
    "                            y_train,\n",
    "                            batch_size=60,\n",
    "                            epochs=700,\n",
    "                            validation_data=(X_val, y_val),\n",
    "                            callbacks=[early_stopping])\n",
    "\n",
    "        bl = (al+1)\n",
    "        # save the updated weights of the new model\n",
    "        new_model.save_weights(f'{path}/new_model{bl}.h5')\n",
    "        \n",
    "        print (f'saved model : new_model{bl}.h5')\n",
    "        # Make predictions and apply thresholding\n",
    "        y_pred = new_model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(5):\n",
    "            z = images_name[i]\n",
    "            binary_mask = y_pred[i]\n",
    "            plt.imshow(binary_mask)\n",
    "            plt.show()\n",
    "\n",
    "        history.history.keys()\n",
    "        metrics = list(history.history.keys())\n",
    "        plot_segm_history(history, metrics=metrics)   \n",
    "        plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred, nm_img_to_plot=5)\n",
    "        al += 1\n",
    "        print ('completed iteration number',k,'The value of al is ',al)\n",
    "        print ('#############################')\n",
    "        print()\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6457793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb948ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wtrain(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275a090b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0e4a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "al =99\n",
    "ran=15\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# create a new model with the same architecture as the original model\n",
    "new_model = create_model()\n",
    "\n",
    "path = '/raid/mpsych/RISTERLAB/kiran/flyem/K_Experiments/models'\n",
    "# load the previously saved weights into the new model\n",
    "new_model.load_weights(f'{path}/new_model{al}.h5')\n",
    "# load the saved weights into the new model\n",
    "p = np.random.permutation(len(images))\n",
    "images = images[p]\n",
    "L_test = images[:ran]    \n",
    "X_new_subset = L_test\n",
    "# make predictions on new data\n",
    "y_pred = new_model.predict(X_new_subset)\n",
    "# plot the predictions for the first 10 images\n",
    "for i in range(ran):    \n",
    "    binary_mask = y_pred[i]\n",
    "    plt.imshow(binary_mask)\n",
    "    plt.show()\n",
    "    \n",
    "history.history.keys()\n",
    "metrics = list(history.history.keys())\n",
    "plot_segm_history(history, metrics=metrics)   \n",
    "plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred, nm_img_to_plot=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d5f669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41903987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# select the first 10 images from X_new\n",
    "X_new_subset = X_new[:10]\n",
    "\n",
    "# make predictions on the subset of data\n",
    "y_pred_subset = new_model.predict(X_new_subset)\n",
    "\n",
    "# plot the predictions for the first 10 images\n",
    "plt.plot(y_pred_subset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825681f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8871caca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "from skimage.filters import threshold_otsu\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# create a new model with the same architecture as the original model\n",
    "new_model = create_model()\n",
    "\n",
    "# load the previously saved weights into the new model\n",
    "new_model.load_weights('new_model1.h5')\n",
    "\n",
    "# compile the new model\n",
    "new_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[IoU])\n",
    "\n",
    "# Create an instance of the ImageDataGenerator class\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10, # randomly rotate images up to 10 degrees\n",
    "    width_shift_range=0.1, # randomly shift images horizontally by up to 10%\n",
    "    height_shift_range=0.1, # randomly shift images vertically by up to 10%\n",
    "    horizontal_flip=True, # randomly flip images horizontally\n",
    "    zoom_range=0.1 # randomly zoom in/out on images by up to 10%\n",
    ")\n",
    "# Fit the data generator on your training data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "history = model.fit(\n",
    "                    datagen.flow(X_train, y_train, batch_size=60),                    \n",
    "                    epochs=350,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stopping])\n",
    "# save the updated weights of the new model\n",
    "new_model.save_weights('new_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0a93a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1553c391",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecabb268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(binary_mask):\n",
    "    labeled, number = mh.label(binary_mask)\n",
    "    sizes = mh.labeled.labeled_size(labeled)\n",
    "    print ('sizes:',sizes)\n",
    "    len(sizes)\n",
    "    too_small = np.where(sizes < min_region_size)\n",
    "    labeled_only_big = mh.labeled.remove_regions(labeled, too_small)\n",
    "\n",
    "    ##############\n",
    "\n",
    "    binary_mask = labeled_only_big.copy()\n",
    "    binary_mask[binary_mask > 0] = 1\n",
    "\n",
    "    print('labelled only big')\n",
    "    plt.imshow(binary_mask)\n",
    "    labels(binary_mask)\n",
    "    #######\n",
    "\n",
    "    binary_mask_closed = mh.gaussian_filter(binary_mask, sigma=5)\n",
    "    print('gassuian filter sigma =5')\n",
    "    plt.imshow(binary_mask_closed)\n",
    "    labels(binary_mask_closed)\n",
    "\n",
    "    #######\n",
    "    binary_mask_open=mh.morph.close_holes(binary_mask)\n",
    "    plt.imshow(binary_mask_open)\n",
    "    labels(binary_mask_open)\n",
    "\n",
    "\n",
    "    ##########\n",
    "    for i in range(3):\n",
    "        binary_mask_open = mh.morph.dilate(binary_mask_open)\n",
    "        print('dilate range of 3')\n",
    "        plt.imshow(binary_mask_open)\n",
    "        labels(binary_mask_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1907de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nt_early_pp(batch,epochs,plot,thres):\n",
    "    import cv2\n",
    "    from PIL import Image\n",
    "\n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        batch_size=batch,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        callbacks=[early_stopping])\n",
    "\n",
    "    # Make predictions and apply thresholding\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = (y_pred > thres).astype(np.uint8)\n",
    "\n",
    "    # Calculate precision, recall, and F1 score\n",
    "    #report = classification_report(y_test.flatten(), y_pred.flatten(), target_names=['background', 'circle'], output_dict=True)\n",
    "    #print('Classification report:\\n', report)\n",
    "\n",
    "    # Apply contrast stretching to the predicted images\n",
    "    new_min_value = 0\n",
    "    new_max_value = 255\n",
    "\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        z = images_name[i]\n",
    "        image = Image.fromarray((y_pred[i].squeeze() * 255).astype(np.uint8))\n",
    "        min_value, max_value = image.getextrema()\n",
    "        scale = (new_max_value - new_min_value) / (max_value - min_value)\n",
    "        image = image.point(lambda i: (i - min_value) * scale + new_min_value)\n",
    "        y_pred[i] = np.expand_dims(np.array(image), axis=-1) / 255\n",
    "        print(z)\n",
    "        binary_mask = y_pred[i]\n",
    "        plt.imshow(binary_mask, cmap='gray')\n",
    "        plt.show()\n",
    "        #processing(binary_mask)\n",
    "        \n",
    "        #\n",
    "        \n",
    "        \n",
    "        \n",
    "    # Plotting results\n",
    "    from keras_unet.utils import plot_segm_history\n",
    "    # shutil.copy(os.path.join(path1, z), os.path.join(path2, z))\n",
    "    # save_path = os.path.join(save_dir, image_name[i])\n",
    "    # print(\"Saving image to:\", save_path)\n",
    "    # cv2.imwrite(save_path, y_pred)\n",
    "\n",
    "#     history.history.keys()\n",
    "#     metrics = list(history.history.keys())\n",
    "#     plot_segm_history(history, metrics=metrics)   \n",
    "#     plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred, nm_img_to_plot=plot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ffb907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0523ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled, number = mh.label(binary_mask)\n",
    "    sizes = mh.labeled.labeled_size(labeled)\n",
    "    #print ('sizes:',sizes)\n",
    "    a = len(sizes)\n",
    "    print ('length of sizes =',a)\n",
    "    too_small = np.where(sizes < min_region_size)\n",
    "    labeled_only_big = mh.labeled.remove_regions(labeled, too_small)\n",
    "\n",
    "    ##############\n",
    "\n",
    "    binary_mask = labeled_only_big.copy()\n",
    "    binary_mask[binary_mask > 0] = 1\n",
    "\n",
    "    print('labelled only big')\n",
    "    plt.imshow(binary_mask)\n",
    "    labels(binary_mask)\n",
    "    #######\n",
    "\n",
    "    binary_mask_closed = mh.gaussian_filter(binary_mask, sigma=5)\n",
    "    print('gassuian filter sigma =5')\n",
    "    plt.imshow(binary_mask_closed)\n",
    "    labels(binary_mask_closed)\n",
    "\n",
    "    #######\n",
    "    binary_mask_open=mh.morph.close_holes(binary_mask)\n",
    "    plt.imshow(binary_mask_open)\n",
    "    labels(binary_mask_open)\n",
    "\n",
    "\n",
    "    ##########\n",
    "    for i in range(3):\n",
    "        binary_mask_open = mh.morph.dilate(binary_mask_open)\n",
    "        print('dilate range of 3')\n",
    "        plt.imshow(binary_mask_open)\n",
    "        labels(binary_mask_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4260b33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "binary_mask = labeled_only_big.copy()\n",
    "binary_mask[binary_mask > 0] = 1\n",
    "\n",
    "#binary_mask = mh.morph.close(binary_mask)\n",
    "# Plot the binary mask\n",
    "plt.imshow(binary_mask, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# Calculate number_1\n",
    "labeled, num = mh.label(binary_mask)\n",
    "print(\"Number_1:\", num)\n",
    "\n",
    "# Calculate region sizes\n",
    "region_sizes = measure.regionprops(labeled, intensity_image=binary_mask)\n",
    "sizes = [region.area for region in region_sizes]\n",
    "\n",
    "# Find min_region_size\n",
    "sizes.sort()\n",
    "large_region_start_index = next((i for i in range(1,len(sizes)) if sizes[i] - sizes[i-1] > 100), len(sizes))\n",
    "min_region_size = (sizes[large_region_start_index-1] + sizes[large_region_start_index]) // 2\n",
    "print(\"Min_region_size:\", min_region_size)\n",
    "\n",
    "# Calculate large_regions\n",
    "num_large_regions = 0\n",
    "for region in region_sizes:\n",
    "    if region.area > min_region_size:\n",
    "        num_large_regions += 1\n",
    "print(\"Large_regions:\", num_large_regions)\n",
    "\n",
    "# Calculate threshold\n",
    "thresh = filters.threshold_otsu(binary_mask)\n",
    "print(\"Threshold:\", thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1798cc3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0f4c52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4d3780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc88f5f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8842e18a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6fe7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d72662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### POST PROCESSING###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9009d8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the binary image\n",
    "image = cv2.imread('image.png', 0)\n",
    "\n",
    "# Find the contours in the image\n",
    "contours, _ = cv2.findContours(image, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Calculate the sizes and thicknesses of the contours\n",
    "sizes = []\n",
    "thicknesses = []\n",
    "for contour in contours:\n",
    "    size = cv2.contourArea(contour)\n",
    "    perimeter = cv2.arcLength(contour, True)\n",
    "    thickness = 4 * np.pi * size / (perimeter ** 2)\n",
    "    sizes.append(size)\n",
    "    thicknesses.append(thickness)\n",
    "\n",
    "# Calculate the mean and standard deviation of the sizes and thicknesses\n",
    "mean_size = np.mean(sizes)\n",
    "std_size = np.std(sizes)\n",
    "mean_thickness = np.mean(thicknesses)\n",
    "std_thickness = np.std(thicknesses)\n",
    "\n",
    "# Set the minimum size and thickness for the contours\n",
    "min_size = mean_size - std_size\n",
    "min_thickness = mean_thickness - std_thickness\n",
    "\n",
    "# Calculate the distances between the contours\n",
    "distances = []\n",
    "for contour1 in contours:\n",
    "    for contour2 in contours:\n",
    "        if contour1 is not contour2:\n",
    "            dist = cv2.pointPolygonTest(contour1, tuple(contour2[0][0]), True)\n",
    "            distances.append(abs(dist))\n",
    "\n",
    "# Calculate the median of the distances\n",
    "median_distance = np.median(distances)\n",
    "\n",
    "# Set the distance threshold for the pointPolygonTest function\n",
    "distance_threshold = median_distance\n",
    "\n",
    "# Create a mask to store the filtered contours\n",
    "mask = np.zeros_like(image)\n",
    "\n",
    "# Iterate through the contours\n",
    "for contour in contours:\n",
    "    # Calculate the size and thickness of the contour\n",
    "    size = cv2.contourArea(contour)\n",
    "    perimeter = cv2.arcLength(contour, True)\n",
    "    thickness = 4 * np.pi * size / (perimeter ** 2)\n",
    "\n",
    "    # Check if the contour is close to any larger regions\n",
    "    close_to_larger_region = False\n",
    "    for other_contour in contours:\n",
    "        if cv2.contourArea(other_contour) > size:\n",
    "            dist = cv2.pointPolygonTest(other_contour, tuple(contour[0][0]), True)\n",
    "            if abs(dist) < distance_threshold:\n",
    "                close_to_larger_region = True\n",
    "                break\n",
    "\n",
    "    # If the contour is large enough or close to a larger region or thick enough, add it to the mask\n",
    "    if size > min_size or close_to_larger_region or thickness > min_thickness:\n",
    "        cv2.drawContours(mask, [contour], -1, 255, -1)\n",
    "\n",
    "# Apply the mask to the image to remove the small white dots\n",
    "result = cv2.bitwise_and(image, mask)\n",
    "\n",
    "# Show the result\n",
    "cv2.imshow('Result', result)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
