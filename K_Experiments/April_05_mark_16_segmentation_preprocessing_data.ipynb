{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964e0a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## CPU  BASED ITERATION SEGMENTATION USING TRADITIONAL COMPUTER VISION ##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b8002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pillow\n",
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2f1e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNISNSTALL EXISTING NUMPY MAHATOS AND RE-INSALL IT BEFORE RUNNING THIS ?make sure you have a numpy1.24 or above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba805373",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip uninstall numpy mahotas -y     ## run this two times just to make sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d2a7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall numpy mahotas -y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fcb7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy mahotas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5ea222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import shutil\n",
    "import random\n",
    "import inspect\n",
    "#import imageio as im\n",
    "import numpy as np\n",
    "import mahotas as mh\n",
    "from PIL import Image\n",
    "from tabulate import tabulate\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "#from skimage import measure, filters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e3697d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604a46b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade mahotas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c415029",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### EXCEPT FOR RAW DATA I ALWAYS USE FRESH DIRECTORIES #############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b17599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original directory path and working directory path for images\n",
    "data = \"/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir/raw_files\"\n",
    "working_dir = \"/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be946bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### THE BELOW ARE TEST DIRECTORIES THEY CHANGE BASED ON TESTS  #########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229dd806",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"test3\" # you can change this according to your needs. to access that data.\n",
    "#current experiments are in test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934be3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "real = f\"{working_dir}/{experiment}/real_images\"\n",
    "#########################################################################################################\n",
    "\n",
    "directories = {\n",
    "    \"normalized\": f\"{working_dir}/{experiment}/normalized_images\",\n",
    "    \"cropped\": f\"{working_dir}/{experiment}/cropped_images\",\n",
    "    \"npy\": f\"{working_dir}/{experiment}/pre_processing/npy\",\n",
    "    \"originals\": f\"{working_dir}/{experiment}/pre_processing/originals\",\n",
    "    \"masks\": f\"{working_dir}/{experiment}/pre_processing/masks\",\n",
    "    \"test\": f\"{working_dir}/{experiment}/pre_processing/test\",\n",
    "    \"s\": f\"{working_dir}/{experiment}/S\",\n",
    "    \"crop_original\": f\"{working_dir}/{experiment}/pre_processing/crop_originals\",\n",
    "    \"crop_masks\": f\"{working_dir}/{experiment}/pre_processing/crop_masks\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc40d072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c159d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################functions\n",
    "start_time = 0  # Define start_time in the global scope\n",
    "\n",
    "def starttime():\n",
    "    global start_time  # Use the global keyword to access the global start_time variable\n",
    "    start_time = time.time()\n",
    "    #hint: starttime() - To start timer.\n",
    "    \n",
    "def endtime():\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"Execution time: {execution_time:.2f} seconds\")\n",
    "    #hint: endtime() - To end timer\n",
    "\n",
    "def check(path):\n",
    "    # Create the directory if it does not exist\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    # Remove the directory and all its contents\n",
    "    shutil.rmtree(path)\n",
    "\n",
    "    # Create a new empty directory\n",
    "    os.mkdir(path)\n",
    "    #hint: check(path) - To recreate a particular path\n",
    "            \n",
    "def heavycrop(test):\n",
    "    starttime()\n",
    "    for z in tqdm(sorted(os.listdir(test))):\n",
    "        if z.endswith(\"tif\"):\n",
    "            # Read in the image\n",
    "            img = mh.imread(os.path.join(test, z))\n",
    "\n",
    "            # Calculate the number of crops in each dimension\n",
    "            height, width = img.shape[:2]\n",
    "            num_crops_y = height // 512\n",
    "            num_crops_x = width // 512\n",
    "\n",
    "            for i in range(num_crops_y):\n",
    "                for j in range(num_crops_x):\n",
    "                    # Crop the image\n",
    "                    start_y = i * 512\n",
    "                    start_x = j * 512\n",
    "                    img_cropped = img[start_y:start_y+512, start_x:start_x+512]\n",
    "\n",
    "                    # Create a new file name for the cropped image\n",
    "                    file_name, file_ext = os.path.splitext(z)\n",
    "                    new_file_name = f\"{file_name}_{i}_{j}{file_ext}\"\n",
    "\n",
    "                    # Save only if cropped image has shape (512, 512)\n",
    "                    if img_cropped.shape == (512, 512):\n",
    "                        mh.imsave(os.path.join(test, new_file_name), img_cropped)\n",
    "                    else:\n",
    "                        print(f\"Warning: Cropped image has unexpected shape {img_cropped.shape}\")\n",
    "                        \n",
    "            endtime()\n",
    "            # Remove original image file after cropping is done.\n",
    "            os.remove(os.path.join(test,z))\n",
    "            #hint: heavycrop(spath) - To heavy crop all images 512x512\n",
    "            \n",
    "def npyconversion(tif_dir, npy_path):\n",
    "    tif_files = [f for f in os.listdir(tif_dir) if f.endswith('.tif')]\n",
    "    tif_files.sort()\n",
    "    data = []\n",
    "    for tif_file in tqdm(tif_files):\n",
    "        img = Image.open(os.path.join(tif_dir, tif_file))\n",
    "        data.append(np.array(img))\n",
    "    np.save(npy_path, data)\n",
    "    #hint: npyconversion(path , npy + '/filename.npy' ) -To create NPY files\n",
    "            \n",
    "def a2bcopy(path1, path2):\n",
    "    for z in tqdm(sorted(os.listdir(path1))):\n",
    "        if z.endswith(\"tif\"):\n",
    "            shutil.copy(os.path.join(path1, z), os.path.join(path2, z))\n",
    "            #hint: a2bcopy(sorce path, dest path) - To copy all images\n",
    "            \n",
    "def crop(test):\n",
    "    for z in tqdm(sorted(os.listdir(test))):\n",
    "        if (z.endswith(\"tif\")): # checking the file ends with tif\n",
    "            # Read in the image\n",
    "            img = mh.imread(os.path.join(test, z))\n",
    "            img_cropped = img[1000:2500, 2500:4500]\n",
    "            mh.imsave(os.path.join(test, z), img_cropped)\n",
    "            print(z)\n",
    "            #hint: crop(spath) - To crop all images\n",
    "    \n",
    "def a2brandom(src_dir, dst_dir, number):\n",
    "    # Get a list of all image files in the source directory\n",
    "    image_files = [f for f in tqdm(os.listdir(src_dir)) if f.endswith('.tif')]\n",
    "    # Randomly select 10 images from the list\n",
    "    selected_images = random.sample(image_files, number)\n",
    "    # Copy the selected images to the destination directory\n",
    "    for image in selected_images:\n",
    "        src_path = os.path.join(src_dir, image)\n",
    "        dst_path = os.path.join(dst_dir, image)\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "    # Print a message when done\n",
    "    print('Copied 10 random images to', dst_dir)\n",
    "    #hint: a2brandom(sorce path, dest path, random number) - To copy n random images\n",
    "    \n",
    "def count_files(dir_path):\n",
    "    if os.path.isdir(dir_path):\n",
    "        file_count = 0\n",
    "        for file_name in os.listdir(dir_path):\n",
    "            file_path = os.path.join(dir_path, file_name)\n",
    "            file_size_bytes = os.path.getsize(file_path)\n",
    "            file_size_mb = round(file_size_bytes / (1024 * 1024), 2)\n",
    "            #print(f'{file_name} - Size: {file_size_mb} MB')\n",
    "            file_count += 1\n",
    "        return file_count\n",
    "    else:\n",
    "        print(f\"{dir_path} is not a valid directory\")\n",
    "        return 0    \n",
    "        #hint: count_files(path) - To count number of files in that path\n",
    "    \n",
    "def norm(path):\n",
    "    for z in tqdm(sorted(os.listdir(path))):# added interactive progressbar to decrease the uncertanity and to increase curiosity :)\n",
    "        if (z.endswith(\"tif\")): # checking the file ends with tif \n",
    "            img = mh.imread(os.path.join(path, z))            \n",
    "            # Normalize the image\n",
    "            img = img.astype(np.float64)\n",
    "            img /= img.max()\n",
    "            img *= 255            \n",
    "            # Save the processed image back to the temporary directory\n",
    "            mh.imsave(os.path.join(path, z), img)\n",
    "            #hint: norm(path) - To normalize all the images in the path\n",
    "            \n",
    "def shape(raw):\n",
    "    for z in tqdm(sorted(os.listdir(raw))):\n",
    "        if (z.endswith(\"tif\")):\n",
    "            img = mh.imread(os.path.join(raw, z))\n",
    "            print (img.shape)\n",
    "            #hint: shape(path) _ To print shape of all the images in the path\n",
    "            \n",
    "def refresh(experiment: str, directories: dict):\n",
    "    for key in directories:\n",
    "        if os.path.exists(directories[key]):\n",
    "            shutil.rmtree(directories[key])\n",
    "        os.makedirs(directories[key])\n",
    "        #hint: refresh(\"experiment name\", directories) - to recreate all directories in that dict\n",
    "        \n",
    "def paths(directories):\n",
    "    for key, value in directories.items():\n",
    "        globals()[key] = value\n",
    "    return directories\n",
    "    #hint: paths(directories) - To call the directories outside the dictionary\n",
    "        \n",
    "def help():\n",
    "    functions = [value for key, value in globals().items() if inspect.isfunction(value)]\n",
    "    headers = [\"Function\", \"Hint\", \"Used for\"]\n",
    "    data = []\n",
    "    for func in functions:\n",
    "        source = inspect.getsource(func)\n",
    "        lines = source.split(\"\\n\")\n",
    "        hint_line = [line for line in lines if line.strip().startswith(\"#hint:\")]\n",
    "        if hint_line:\n",
    "            hint_parts = hint_line[0].split(\"#hint:\")[1].strip().split(\" - \")\n",
    "            hint_text = hint_parts[0]\n",
    "            usage_text = hint_parts[1] if len(hint_parts) > 1 else \"\"\n",
    "            data.append([f\"{func.__name__}()\", hint_text, usage_text])\n",
    "    print(tabulate(data, headers=headers))\n",
    "            \n",
    "def check_all(directories):\n",
    "    for key, path in directories.items():\n",
    "        if os.path.exists(path):\n",
    "            shutil.rmtree(path)\n",
    "        os.makedirs(path)\n",
    "        #hint: check_all(directories) - To create all directories fresh only use for new experiments.\n",
    "        \n",
    "def readpaths(directories):\n",
    "    for key, path in directories.items():\n",
    "        globals()[key] = path\n",
    "        #hint: readpaths(directories) - To create all directories fresh only use for new experiments.\n",
    "            \n",
    "#def del(path):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cf163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths(directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100b6970",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b62bee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## The below are manual functions to delete any particular directory and create it again. ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566149fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check_all(directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f20171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check(real)\n",
    "# check(normalized)\n",
    "# check(cropped)\n",
    "\n",
    "# check(crop_originals)\n",
    "# check(crop_masks)\n",
    "# check(npy)\n",
    "# check(originals)\n",
    "# check(masks)\n",
    "# check(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6ada03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MANUALLY CHECK THAT ALL FOLDERS ARE AVAILABLE AND EMPTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd8454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################      Getting some random data                ###############################\n",
    "raw = '/raid/mpsych/RISTERLAB/VSOverviewTileSet/Acquired/'\n",
    "raw1 = '/raid/mpsych/RISTERLAB/NINA_D1_MUTANTVSOverviewTileSet/Acquired'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adf72da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a2brandom(raw,data,800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d56986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a2brandom(raw1,data,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dbb241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_files(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d09a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a2bcopy(data,real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddafac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a2bcopy(data,normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11163738",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a2bcopy(data,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe2cb15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#a2bcopy(data,cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f64ef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_files(cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d4bf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############FINISHED COPYING FILES TO DIRECTORIES, NOW Normalization, cropping, segmentation ##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24b8450",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6bcf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#norm(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6fe741",
   "metadata": {},
   "outputs": [],
   "source": [
    "#norm(cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a33a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5133ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crop(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efb7bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crop(cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed408902",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crop(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20a6b35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876663df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#heavycrop(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e788900",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!lspci | grep -i nvidia\n",
    "# TO check the graphic card availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67681a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_files(cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f23eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################    SEGMENTATION BEGIN    #########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8a1810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# success_count=0 \n",
    "# for z in tqdm(sorted(os.listdir(cropped))):\n",
    "#     if (z.endswith(\"tif\")): # checking the file ends with tif \n",
    "#         img = im.imread(os.path.join(cropped, z))\n",
    "#         print (z)\n",
    "#         plt.imshow(img)\n",
    "#         #plt.show()\n",
    "    \n",
    "#         # Apply a Gaussian filter to the image\n",
    "#         c = img.copy()\n",
    "#         #b = mh.gaussian_filter(b, sigma=3)\n",
    "\n",
    "#         # Set values below 100 to 0\n",
    "#         for a in range(150, 0, -1):\n",
    "#             starttime()\n",
    "#             b= img.copy()\n",
    "#             b = mh.gaussian_filter(b, sigma=3)\n",
    "#             b[b < a] = 0\n",
    "#             #print (a)      \n",
    "#             #b = exposure.equalize_hist(b)\n",
    "#             # Label the regions in the filtered image\n",
    "#             labeled, number = mh.label(b)\n",
    "\n",
    "\n",
    "#             # filter based on labeled region size\n",
    "#             sizes = mh.labeled.labeled_size(labeled)\n",
    "\n",
    "#             # Remove the regions that are less than 1000\n",
    "#             too_small = np.where(sizes < 1500)\n",
    "#             labeled_only_big = mh.labeled.remove_regions(labeled, too_small)\n",
    "\n",
    "#             #too_large = np.where(sizes > 20500)\n",
    "#             #labeled_only_big = mh.labeled.remove_regions(labeled, too_large)\n",
    "#             #for debug\n",
    "#             #plt.imshow(labeled_only_big)\n",
    "#             #plt.show()\n",
    "\n",
    "\n",
    "#             # Create a binary mask from the filtered labeled regions\n",
    "#             binary_mask = labeled_only_big.copy()\n",
    "#             binary_mask[binary_mask > 0] = 1\n",
    "#             labeled, number_1 = mh.label(binary_mask)\n",
    "\n",
    "\n",
    "#              # Close the regions in the binary mask\n",
    "#             binary_mask_closed = mh.morph.close(binary_mask)\n",
    "            \n",
    "            \n",
    "#             plt.figure(figsize=(10,10))\n",
    "#             #plt.imshow(binary_mask_closed)\n",
    "#             #plt.show() \n",
    "            \n",
    "#             # Set a threshold for the minimum region size           \n",
    "#             min_region_size = 3000\n",
    "            \n",
    "#             # Initialize a variable to count the number of regions above the minimum size\n",
    "#             large_regions = 0\n",
    "\n",
    "#             # Get the sizes of the labeled regions\n",
    "#             region_sizes = measure.regionprops(labeled, intensity_image=binary_mask_closed)\n",
    "\n",
    "#             # Iterate over the region sizes and count the number of large regions\n",
    "#             for region in region_sizes:\n",
    "#                 if region.area > min_region_size:\n",
    "#                      large_regions += 1\n",
    "\n",
    "\n",
    "#             threshold = filters.threshold_otsu(binary_mask_closed) \n",
    "#             binary_image = binary_mask_closed > threshold\n",
    "#             print('time taken for iteration',a,'image',z ,'is:')\n",
    "#             endtime()\n",
    "# #             if number_1>= 90:                \n",
    "# #                 print (z)\n",
    "# #                 plt.imshow(binary_image)\n",
    "# #                 plt.show()\n",
    "# #                 print (number_1)\n",
    "# #                 print (threshold)\n",
    "# #                 print(large_regions)\n",
    "                  \n",
    "#             if number_1 <=150 and number_1 >=100:\n",
    "#                 if large_regions <=20:       # 20 is ideal value \n",
    "#                     print (\"######################################################################\")\n",
    "#                     print(z)\n",
    "#                     #plt.figure(figsize=(10,10))\n",
    "#                     print(\"The image has clear segmentation.\")\n",
    "#                     #plt.imshow(binary_image)\n",
    "#                     #plt.show()\n",
    "#                     print (number_1)\n",
    "#                     print (threshold)\n",
    "#                     print(large_regions)\n",
    "#                     shutil.move(os.path.join(normalized,z),os.path.join(originals,z))                 \n",
    "#                     shutil.move(os.path.join(cropped,z),os.path.join(masks,z))                 \n",
    "#                     mh.imsave(os.path.join(masks,z),binary_image)                 \n",
    "#                     #print (sizes)\n",
    "#                     print (\"######################################################################\")\n",
    "#                     success_count+=1\n",
    "#                     print (success_count)\n",
    "#                     break\n",
    "# print (success_count)\n",
    "# print ('######################################### DONE        ############################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61008f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the files which got segemented well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62817614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# origi = int(count_files(masks))\n",
    "# croppi = int(count_files(real))\n",
    "# seg_well =(((origi)/(croppi))*100) \n",
    "# print (\"percentage = \",seg_well ,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551bb73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_files(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075cb5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (\"sucessfilly segemented\", origi,\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ca235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################   SEGMENTATION END   ################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef25870",
   "metadata": {},
   "outputs": [],
   "source": [
    "######copying data for heavycropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e56c9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a2bcopy(masks,crop_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116cc5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a2bcopy(originals,crop_originals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130da0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#heavycrop(crop_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcde6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#heavycrop(crop_originals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc8e57e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8884b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_files(crop_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46236cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_files(crop_originals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eb8c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "readpaths(directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae046f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = \"/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir/test2/pre_processing/originals\"\n",
    "mask = \"/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir/test2/pre_processing/masks\"\n",
    "npy1 = \"/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir/test3/pre_processing/npy1\"\n",
    "pp=\"/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir/test3/post_processing/processed_prediction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b08ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ap=\"/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir/test3/post_processing/op\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267a24f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_files(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53420f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_files(crop_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c2d468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def a2bcopyforzinc(src,dst,c):\n",
    "    for z in tqdm(sorted(os.listdir(c))):\n",
    "        if (z.endswith(\"tif\")):\n",
    "            shutil.copy(os.path.join(src,z),os.path.join(dst,z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3130556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a2bcopyforzinc(crop_original,ap,pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1332c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_files(ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32de639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a2bcopy(original,crop_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e558cbae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#a2bcopy(mask,crop_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860e5825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d70982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def npycon(tif_dir, npy_path):\n",
    "    tif_files = [f for f in os.listdir(tif_dir) if f.endswith('.tif')]\n",
    "    data = []\n",
    "    image_names = []\n",
    "    for tif_file in tqdm(tif_files):\n",
    "        img = Image.open(os.path.join(tif_dir, tif_file))\n",
    "        data.append(np.array(img))\n",
    "        image_names.append(tif_file)\n",
    "    np.savez(npy_path, data=data, names=image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ae534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pom='/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir/test3/post_processing/data_population/old_mask'\n",
    "poo ='/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir/test3/post_processing/data_population/old_original'\n",
    "pno ='/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir/test3/post_processing/data_population/originals'\n",
    "pnm ='/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir/test3/post_processing/data_population/masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d086b4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#npycon(poo, npy1 + '/poo.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e649ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#npycon(pom, npy1 + '/pom.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b720ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "npycon(pno, npy1 + '/pno.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd7da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "npycon(pnm, npy1 + '/pnm.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9060df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#npycon(ap, npy1 + '/new_originals.npz' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538f63a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#npycon(crop_original, npy1 + '/original.npz' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a7dfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#npycon(crop_masks, npy1 + '/mask.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50391435",
   "metadata": {},
   "outputs": [],
   "source": [
    "#npyconversion(crop_original, npy + '/original.npy' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba08853",
   "metadata": {},
   "outputs": [],
   "source": [
    "#npyconversion(crop_masks, npy + '/mask.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedb25dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#npyconversion(test, npy + '/test.npy' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ece825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_files(npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f37e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### run this command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c3162c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy==1.19.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8357714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################  KERAS  #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb3db74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras-unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150a1f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import shutil\n",
    "import random\n",
    "import inspect\n",
    "#import imageio as im\n",
    "import numpy as np\n",
    "import mahotas as mh\n",
    "from PIL import Image\n",
    "from tabulate import tabulate\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "#from skimage import measure, filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef84d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original directory path and working directory path for images\n",
    "data = \"/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir/raw_files\"\n",
    "working_dir = \"/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir\"\n",
    "######################################################################################################\n",
    "experiment = \"test2\" \n",
    "######################################################################################################\n",
    "real = f\"{working_dir}/{experiment}/real_images\"\n",
    "#########################################################################################################\n",
    "\n",
    "directories = {\n",
    "    \"normalized\": f\"{working_dir}/{experiment}/normalized_images\",\n",
    "    \"cropped\": f\"{working_dir}/{experiment}/cropped_images\",\n",
    "    \"npy\": f\"{working_dir}/{experiment}/pre_processing/npy\",\n",
    "    \"originals\": f\"{working_dir}/{experiment}/pre_processing/originals\",\n",
    "    \"masks\": f\"{working_dir}/{experiment}/pre_processing/masks\",\n",
    "    \"test\": f\"{working_dir}/{experiment}/pre_processing/test\",\n",
    "    \"s\": f\"{working_dir}/{experiment}/S\",\n",
    "    \"crop_original\": f\"{working_dir}/{experiment}/pre_processing/crop_originals\",\n",
    "    \"crop_masks\": f\"{working_dir}/{experiment}/pre_processing/crop_masks\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a691756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras_unet.models import custom_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4884f7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "npy = f\"{working_dir}/{experiment}/pre_processing/npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712fabc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_file = os.path.join(npy, 'original.npy')\n",
    "labels_file = os.path.join(npy, 'mask.npy')\n",
    "#test_files = os.path.join(npy, 'test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c666dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load(images_file)\n",
    "labels = np.load(labels_file)\n",
    "#test = np.load(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68111694",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfb1855",
   "metadata": {},
   "outputs": [],
   "source": [
    " # full dataset does not have the last channel\n",
    "images = images.reshape(images.shape[0],images.shape[1],images.shape[2],1)\n",
    "labels = labels.reshape(labels.shape[0],labels.shape[1],labels.shape[2],1)\n",
    "#test = test.reshape(test.shape[0],test.shape[1],test.shape[2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297420b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c495ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.random.permutation(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2283d8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images[p]\n",
    "labels = labels[p]\n",
    "#test = test[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f342762",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc746342",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.astype(np.float64)\n",
    "for i in range(images.shape[0]):\n",
    "    images[i] = (images[i] - images[i].min()) / (images[i].max() - images[i].min()) # normalize individually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d25d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a79e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = images[0:1200]\n",
    "y_train = labels[0:1200]\n",
    "X_val = images[1201:1700]\n",
    "y_val = labels[1201:1700]\n",
    "X_test = images[1701:1812]\n",
    "y_test = labels[1701:1812]\n",
    "\n",
    "#X_test = test[80:]\n",
    "#y_test = test[80:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d655d20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = custom_unet(\n",
    "    input_shape=(512, 512, 1),\n",
    "    use_batch_norm=False,\n",
    "    num_classes=1,\n",
    "    filters=32,\n",
    "    dropout=0.5,\n",
    "    output_activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509b5258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.optimizers\n",
    "from keras_unet.metrics import iou, iou_thresholded\n",
    "from keras_unet.losses import jaccard_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c25b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6136c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizer_v1.Adam(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93d09ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'Adam',    \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=[iou, iou_thresholded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6b24cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### batch size 50 , epochs =1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113f685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(batch,epochs):\n",
    "    print (\"training and prediction for\",\"batch size:  \",batch, \"epochs:  \", epochs)\n",
    "    history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    batch, \n",
    "                    epochs=epochs,\n",
    "                    validation_data=(X_val, y_val), \n",
    "                    verbose=1)\n",
    "    \n",
    "    from keras_unet.utils import plot_segm_history\n",
    "\n",
    "    plot_segm_history(history)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    from keras_unet.utils import plot_imgs\n",
    "\n",
    "    plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred, nm_img_to_plot=100)# number to plot also need to e defined in function\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfa0ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import regularizers\n",
    "# from keras.layers import Dense\n",
    "# from keras.callbacks import EarlyStopping\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras_unet.utils import plot_segm_history, plot_imgs\n",
    "\n",
    "# def training(batch, epochs):\n",
    "#     print(\"training and prediction for\", \"batch size: \", batch, \"epochs: \", epochs)\n",
    "\n",
    "# #     # Regularization\n",
    "#     layer = Dense(units=64,\n",
    "#                   kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01),\n",
    "#                   bias_regularizer=regularizers.l2(0.01))\n",
    "\n",
    "    # Early stopping\n",
    "    #early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "#     # Data augmentation\n",
    "#     datagen = ImageDataGenerator(rotation_range=20,\n",
    "#                                  width_shift_range=0.2,\n",
    "#                                  height_shift_range=0.2,\n",
    "#                                  horizontal_flip=True)\n",
    "#     datagen.fit(X_train)\n",
    "\n",
    "#     # Training with data augmentation\n",
    "#     history = model.fit(datagen.flow(X_train, y_train, batch_size=batch),\n",
    "#                         steps_per_epoch=len(X_train) / batch,\n",
    "#                         epochs=epochs,\n",
    "#                         validation_data=(X_val, y_val),\n",
    "#                         callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "########################################ONLY EARLY STOPPING###################################\n",
    "#     # Early stopping\n",
    "#     early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "#     # Training with early stopping\n",
    "#     history = model.fit(X_train,\n",
    "#                         y_train,\n",
    "#                         batch_size=batch,\n",
    "#                         epochs=epochs,\n",
    "#                         validation_data=(X_val, y_val),\n",
    "#                         callbacks=[early_stopping])\n",
    "\n",
    "#     # Plotting results\n",
    "#     plot_segm_history(history)\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred, nm_img_to_plot=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0002b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_unet.utils import plot_segm_history, plot_imgs\n",
    "\n",
    "def trainingearlystopping(batch, epochs):\n",
    "    print(\"training and prediction for\", \"batch size: \", batch, \"epochs: \", epochs)\n",
    "########################################ONLY EARLY STOPPING###################################\n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "    # Training with early stopping\n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        batch_size=batch,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        callbacks=[early_stopping])\n",
    "\n",
    "    # Plotting results\n",
    "    plot_segm_history(history)\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Apply thresholding\n",
    "    threshold = 0.2\n",
    "    y_pred_binary = (y_pred > threshold).astype(np.uint8)\n",
    "    plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred, nm_img_to_plot=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9145fc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingearlystopping(60,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6358db50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainingearlystopping(60,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff79002",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainingearlystopping(60,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11feebf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ TRYING THRESHOLD VALUES\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def trainingwiththres(batch, epochs, thresholds, n_images):\n",
    "    print(\"training and prediction for\", \"batch size: \", batch, \"epochs: \", epochs)\n",
    "\n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "    # Training with early stopping\n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        batch_size=batch,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        callbacks=[early_stopping])\n",
    "\n",
    "    # Plotting results\n",
    "    plot_segm_history(history)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Apply multiple thresholds\n",
    "    y_pred_binaries = []\n",
    "    for threshold in thresholds:\n",
    "        y_pred_binary = (y_pred > threshold).astype(np.uint8)\n",
    "        y_pred_binaries.append(y_pred_binary)\n",
    "\n",
    "    # Plot binary masks for multiple thresholds\n",
    "    fig, axes = plt.subplots(n_images, len(thresholds), figsize=(15, 15))\n",
    "    for i in range(n_images):\n",
    "        for j in range(len(thresholds)):\n",
    "            axes[i][j].imshow(y_pred_binaries[j][i])\n",
    "            axes[i][j].set_title(f'Threshold {thresholds[j]}')\n",
    "            axes[i][j].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e72ae8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "thresholds = [0.2, 0.4, 0.6, 0.8]\n",
    "n_images = 10\n",
    "history = trainingwiththres(60, 100, thresholds, n_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58aefbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db0559b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcbf20f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d802ccd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fcb3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c30a50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f8c72c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e52631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba311bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967e9a45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a04400e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b077b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#training(60,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46d5fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# a little overlifting has been noticed in the above graph so we are using new techiniques to decrease that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c589d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training(60,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31ebb9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cab8945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7470ba18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c658588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7fdf01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9c72b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84af0363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc49fda0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f13d9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0972bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2de846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603eeb77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d343dff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2b098e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    50, \n",
    "                    epochs=1000,\n",
    "                    validation_data=(X_val, y_val), \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847076ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_unet.utils import plot_segm_history\n",
    "\n",
    "plot_segm_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89f181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1d5c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_unet.utils import plot_imgs\n",
    "\n",
    "plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred, nm_img_to_plot=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5afdbe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0faf44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training(60,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cf401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf761767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training(65,65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4bcf86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "overlay(directories['originals'],directories['masks'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c30a823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf6b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "training(60,4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbeb5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training(64,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4261465b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e02d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa5006b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87843d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "def overlay(original_dir, mask_dir, n):\n",
    "    original_images = os.listdir(original_dir)\n",
    "    mask_images = os.listdir(mask_dir)\n",
    "\n",
    "    for i in range(n):\n",
    "        original_image = random.choice(original_images)\n",
    "        mask_image = original_image.replace('.png', '_mask.png')\n",
    "        if mask_image in mask_images:\n",
    "            img = Image.open(os.path.join(original_dir, original_image))\n",
    "            mask = Image.open(os.path.join(mask_dir, mask_image))\n",
    "            img.paste(mask, (0, 0), mask)\n",
    "            img.show()\n",
    "            #hint: # overlay_masks('original', 'masks', 3) - To plot overlay wiht masks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91cce3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras-unet\n",
    "\n",
    "# import keras\n",
    "# from keras_unet.models import custom_unet\n",
    "\n",
    "# images_file = os.path.join(npy_files, 'original.npy')\n",
    "# labels_file = os.path.join(npy_files, 'mask.npy')\n",
    "\n",
    "# images = np.load(images_file)\n",
    "# labels = np.load(labels_file)\n",
    "\n",
    "# images.shape\n",
    "\n",
    "# # full dataset does not have the last channel\n",
    "# images = images.reshape(images.shape[0],images.shape[1],images.shape[2],1)\n",
    "# labels = labels.reshape(labels.shape[0],labels.shape[1],labels.shape[2],1)\n",
    "\n",
    "# images.shape\n",
    "\n",
    "# p = np.random.permutation(len(images))\n",
    "\n",
    "# images = images[p]\n",
    "# labels = labels[p]\n",
    "\n",
    "# labels = labels.astype(np.float64)\n",
    "\n",
    "# images = images.astype(np.float64)\n",
    "\n",
    "# for i in range(images.shape[0]):\n",
    "#     images[i] = (images[i] - images[i].min()) / (images[i].max() - images[i].min()) # normalize individually\n",
    "\n",
    "\n",
    "# images.shape\n",
    "\n",
    "# X_train = images[0:50]\n",
    "# y_train = labels[0:50]\n",
    "# X_val = images[10:20]\n",
    "# y_val = labels[10:20]\n",
    "# X_test = images[0:]\n",
    "# y_test = labels[0:]\n",
    "\n",
    "# model = custom_unet(\n",
    "#     input_shape=(512, 512, 1),\n",
    "#     use_batch_norm=False,\n",
    "#     num_classes=1,\n",
    "#     filters=32,\n",
    "#     dropout=0.5,\n",
    "#     output_activation='sigmoid')\n",
    "\n",
    "# import keras.optimizers\n",
    "# from keras_unet.metrics import iou, iou_thresholded\n",
    "# from keras_unet.losses import jaccard_distance\n",
    "\n",
    "\n",
    "\n",
    "# opt = keras.optimizer_v1.Adam(lr=0.01)\n",
    "\n",
    "# model.compile(optimizer = 'Adam',    \n",
    "#               loss='binary_crossentropy', \n",
    "#               metrics=[iou, iou_thresholded])\n",
    "\n",
    "# history = model.fit(X_train, \n",
    "#                     y_train, \n",
    "#                     50, \n",
    "#                     epochs=500,\n",
    "#                     validation_data=(X_val, y_val), \n",
    "#                     verbose=1)\n",
    "\n",
    "# from keras_unet.utils import plot_segm_history\n",
    "\n",
    "# plot_segm_history(history)\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# from keras_unet.utils import plot_imgs\n",
    "\n",
    "# plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred, nm_img_to_plot=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef9bf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My next idea in the pipe line is to compare same images on different iterations and come to conclusion.\n",
    "# To decide what batch size and epochs gives the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdb788f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
