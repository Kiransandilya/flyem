{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f009678",
   "metadata": {},
   "outputs": [],
   "source": [
    "                           # Task - 1 ( preparing the data for segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416cdf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536457c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "import mahotas as mh\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import measure, filters, exposure\n",
    "\n",
    "\n",
    "\n",
    "#new funtions added\n",
    "from tqdm.notebook import tqdm\n",
    "import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66d1f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original directory path and working directory path for images\n",
    "data = \"/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir\"\n",
    "data_dir = data\n",
    "raw_files = data + \"/raw_files\"\n",
    "DATA_DIR = raw_files\n",
    "good_images_mask = data + \"/good_images/mask\"\n",
    "good_images_original = data + \"/good_images/original\"\n",
    "npy_files = data_dir + \"/npy_files\"\n",
    "temp_dir = data_dir + \"/temp_dir\"\n",
    "cropped_dir = data_dir + \"/cropped_images\"\n",
    "pre_dir = data_dir + \"/pre_images\"\n",
    "print (data_dir)\n",
    "print (raw_files)\n",
    "print (good_images_mask)\n",
    "print (good_images_original)\n",
    "print (npy_files)\n",
    "print (temp_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f99140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original directory path and working directory path for images\n",
    "data = \"/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir/raw_files\"\n",
    "working_dir = \"/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir\"\n",
    "\n",
    "###########################################################################################\n",
    "real = working_dir + \"/test2/real_images\"\n",
    "normalized = working_dir + \"/test2/normalized_images\"\n",
    "cropped = working_dir + \"/test2/cropped_images\"\n",
    "npy = working_dir + \"/test2/pre_processing/npy\"\n",
    "originals = working_dir + \"/test2/pre_processing/originals\"\n",
    "masks = working_dir + \"/test2/pre_processing/masks\"\n",
    "test = working_dir + \"/test2/pre_processing/test\"\n",
    "s = working_dir + \"/test2/S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf65fd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the images\n",
    "slices = []\n",
    "slice_address = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d876d852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for any existing folders in the path, if there are any removing the old and creating new directories.\n",
    "\n",
    "if os.path.exists(temp_dir):\n",
    "            shutil.rmtree(temp_dir)\n",
    "            os.mkdir(temp_dir)\n",
    "else:\n",
    "            os.mkdir(temp_dir)\n",
    "\n",
    "if os.path.exists(good_images_mask):\n",
    "            shutil.rmtree(good_images_mask)\n",
    "            os.mkdir(good_images_mask)\n",
    "else:\n",
    "            os.mkdir(good_images_original)\n",
    "\n",
    "if os.path.exists(good_images_original):\n",
    "            shutil.rmtree(good_images_original)\n",
    "            os.mkdir(good_images_original)\n",
    "else:\n",
    "            os.mkdir(good_images_original)\n",
    "        \n",
    "if os.path.exists(npy_files):\n",
    "            shutil.rmtree(npy_files)\n",
    "            os.mkdir(npy_files)\n",
    "else:\n",
    "            os.mkdir(npy_files)\n",
    "        \n",
    "if os.path.exists(cropped_dir):\n",
    "            shutil.rmtree(cropped_dir)\n",
    "            os.mkdir(cropped_dir)\n",
    "else:\n",
    "            os.mkdir(cropped_dir)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99437ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copying the files from the RAW source to a temporary source for processing.\n",
    "# added interactive progressbar to decrease the uncertanity and to increase curiosity :)\n",
    "for z in tqdm(os.listdir(DATA_DIR)):\n",
    "    # Check if the file ends with \"tif\"\n",
    "    if z.endswith(\"tif\"):\n",
    "         shutil.copy(os.path.join(DATA_DIR, z), os.path.join(temp_dir, z))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101947b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################NEEDS TO BE FIXED#################################\n",
    "# #f.check(cropped_dir)\n",
    "# def check(dir_path):\n",
    "#     if os.path.isdir(dir_path):\n",
    "#         #check(dir_path)\n",
    "#         for file_name in os.listdir(dir_path):\n",
    "#             file_path = os.path.join(dir_path, file_name)\n",
    "#             file_size = os.path.getsize(file_path)\n",
    "#             file_ctime = time.ctime(os.path.getctime(file_path))\n",
    "#             print(f'{file_name} - Size: {file_size} bytes - Created: {file_ctime}')\n",
    "#     else:\n",
    "#         print(f\"{dir_path} is not a valid directory\")\n",
    "#     check(cropped_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22b2d43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3d6bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################THIS ONE KIND OF APPROACH############\n",
    "###############Normalize-crop approach#############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea02e96f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e660a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying the files to cropped_dir vefore normalization so that temp_dir files won't be tampered and can\n",
    "#be used as original images for training.           \n",
    "for file_name in tqdm(sorted(os.listdir(temp_dir))):\n",
    "    if file_name.endswith('.tif'):\n",
    "        file_path = os.path.join(temp_dir, file_name)\n",
    "        shutil.copy(file_path, cropped_dir)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f3331d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.normalize(cropped) #you can use this function.\n",
    "\n",
    "# thinking of writing a code which will make a copy of 512*512 images after it breaks by every pixel by pixel move\n",
    "\n",
    "# thinkin of writing a code which will make a copy of 512*512 images into multiple\n",
    "# added interactive progressbar to decrease the uncertanity and to increase curiosity :)\n",
    "\n",
    "# for z in tqdm(sorted(os.listdir(temp_dir))):\n",
    "#     if (z.endswith(\"tif\")): # checking the file ends with tif \n",
    "#         # Read in the image\n",
    "#         img = mh.imread(os.path.join(temp_dir, z))\n",
    "\n",
    "#         # Normalize the image\n",
    "#         img = img.astype(np.float)\n",
    "#         img /= img.max()\n",
    "#         img *= 255\n",
    "\n",
    "#         # Save the processed image back to the temporary directory\n",
    "#         mh.imsave(os.path.join(temp_dir, z), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f76b3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cropping images\n",
    "#f.crop(temp_dir)\n",
    "# thinking of writing a code which will make a copy of 512*512 images after it breaks by every pixel by pixel move\n",
    "\n",
    "# thinkin of writing a code which will make a copy of 512*512 images into multiple\n",
    "#For images in temporary folder reading them and cropping them to make it easy for segmentation.\n",
    "def crop_images(cropped_dir):\n",
    "    slices = []\n",
    "    for z in tqdm(sorted(os.listdir(cropped_dir))):\n",
    "        if z.endswith(\"tif\"):\n",
    "            # Read in the image\n",
    "            img = mh.imread(os.path.join(cropped_dir, z))\n",
    "            \n",
    "            # Calculate the number of crops in each dimension\n",
    "            height, width = img.shape[:2]\n",
    "            num_crops_y = height // 512\n",
    "            num_crops_x = width // 512\n",
    "            \n",
    "            for i in range(num_crops_y):\n",
    "                for j in range(num_crops_x):\n",
    "                    # Crop the image\n",
    "                    start_y = i * 512\n",
    "                    start_x = j * 512\n",
    "                    img_cropped = img[start_y:start_y+512, start_x:start_x+512]\n",
    "                    \n",
    "                    # Create a new file name for the cropped image\n",
    "                    file_name, file_ext = os.path.splitext(z)\n",
    "                    new_file_name = f\"{file_name}_{i}_{j}{file_ext}\"\n",
    "                    \n",
    "                    # Copying temp images to cropped images folder\n",
    "                    #shutil.copy(os.path.join(temp_dir, z), os.path.join(cropped_dir, new_file_name))\n",
    "                    \n",
    "                    # Save the processed image back to the cropped directory\n",
    "                    mh.imsave(os.path.join(cropped_dir, new_file_name), img_cropped)\n",
    "                    \n",
    "                    # Add the image to the list\n",
    "                    slices.append(img_cropped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90121376",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crop_images(cropped_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72dfdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_images(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a74689d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef35246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e9470e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02293a80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5286ac56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5f0d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_files(dir_path):\n",
    "    if os.path.isdir(dir_path):\n",
    "        file_count = 0\n",
    "        for file_name in os.listdir(dir_path):\n",
    "            file_path = os.path.join(dir_path, file_name)\n",
    "            file_size_bytes = os.path.getsize(file_path)\n",
    "            file_size_mb = round(file_size_bytes / (1024 * 1024), 2)\n",
    "            #print(f'{file_name} - Size: {file_size_mb} MB')\n",
    "            file_count += 1\n",
    "        return file_count\n",
    "    else:\n",
    "        print(f\"{dir_path} is not a valid directory\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e67d7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_files(temp_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea02cbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_files(cropped_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4685a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9c832c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e002c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac4ab13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579b3877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babff124",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_dir = data_dir + \"/pre_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ceb9fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MASKING  Style -1\n",
    "\n",
    "#from skimage import exposure\n",
    "\n",
    "for z in tqdm(sorted(os.listdir(cropped_dir))):\n",
    "    if (z.endswith(\"tif\")): # checking the file ends with tif \n",
    "        img = mh.imread(os.path.join(cropped_dir, z))\n",
    "    \n",
    "    # Apply a Gaussian filter to the image\n",
    "    b = img.copy()\n",
    "    #b = mh.gaussian_filter(b, sigma=3)\n",
    "    \n",
    "    # Set values below 100 to 0\n",
    "    b[b < 90] = 0\n",
    "    \n",
    "    \n",
    "    #b = exposure.equalize_hist(b)\n",
    "    # Label the regions in the filtered image\n",
    "    labeled, number = mh.label(b)\n",
    "    \n",
    "    \n",
    "    # filter based on labeled region size\n",
    "    sizes = mh.labeled.labeled_size(labeled)\n",
    "    \n",
    "    # Remove the regions that are less than 1000\n",
    "    too_small = np.where(sizes < 5000)\n",
    "    labeled_only_big = mh.labeled.remove_regions(labeled, too_small)\n",
    "    \n",
    "    too_large = np.where(sizes > 20500)\n",
    "    labeled_only_big = mh.labeled.remove_regions(labeled, too_large)\n",
    "    #for debug\n",
    "    #plt.imshow(labeled_only_big)\n",
    "    #plt.show()\n",
    "    \n",
    "    \n",
    "    # Create a binary mask from the filtered labeled regions\n",
    "    binary_mask = labeled_only_big.copy()\n",
    "    binary_mask[binary_mask > 0] = 1\n",
    "    labeled, number_1 = mh.label(binary_mask)\n",
    "    \n",
    "    \n",
    "     # Close the regions in the binary mask\n",
    "    binary_mask_closed = mh.morph.close(binary_mask)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    #plt.imshow(binary_mask_closed)\n",
    "    #plt.show()    \n",
    "    # Set a threshold for the minimum region size\n",
    "    min_region_size = 3000\n",
    "    # Initialize a variable to count the number of regions above the minimum size\n",
    "    large_regions = 0\n",
    "    \n",
    "    # Get the sizes of the labeled regions\n",
    "    region_sizes = measure.regionprops(labeled, intensity_image=binary_mask_closed)\n",
    "        \n",
    "    # Iterate over the region sizes and count the number of large regions\n",
    "    for region in region_sizes:\n",
    "        if region.area > min_region_size:\n",
    "             large_regions += 1\n",
    "                \n",
    "    threshold = filters.threshold_otsu(binary_mask_closed) \n",
    "    binary_image = binary_mask_closed > threshold\n",
    "    print(z)\n",
    "    print(\"The image has clear segmentation.\")\n",
    "    plt.imshow(binary_image)\n",
    "    plt.show()\n",
    "    print (number_1)\n",
    "    print (threshold)\n",
    "    print(large_regions)\n",
    "    print (sizes)\n",
    "    print (\"######################################################################\")\n",
    "    \n",
    "   # if number_1 >=9500:\n",
    "            #shutil.copy(os.path.join(cropped_dir, z), os.path.join(pre_dir, z))\n",
    "            \n",
    "             \n",
    "#         mh.imsave(os.path.join(good_images_mask, z), binary_image)\n",
    "        \n",
    "#         shutil.copy(os.path.join(temp_dir, z), os.path.join(good_images_original, z))\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94db187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_files(pre_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6aaded",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################THIS IS CROP AND NORMALIZE APPROACH###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433495ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c828be85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For images in temporary folder reading them and cropping them to make it easy for segmentation.\n",
    "for z in tqdm(sorted(os.listdir(temp_dir))):\n",
    "    if (z.endswith(\"tif\")): # checking the file ends with tif\n",
    "        # Read in the image\n",
    "        img = mh.imread(os.path.join(temp_dir, z))\n",
    "        # Crop the image\n",
    "        img_cropped = img[1500:2012, 2500:3012]\n",
    "        #copying temp images to cropped images folder\n",
    "        shutil.copy(os.path.join(temp_dir, z), os.path.join(cropped_dir, z))\n",
    "        # Save the processed image back to the temporary directory\n",
    "        mh.imsave(os.path.join(cropped_dir, z), img_cropped)\n",
    "        # Add the image to the list\n",
    "        slices.append(img_cropped)\n",
    "        # Display the image\n",
    "        print(z)\n",
    "       # plt.imshow(img_cropped)\n",
    "       # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e7349",
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in tqdm(sorted(os.listdir(cropped_dir))):\n",
    "    if (z.endswith(\"tif\")): # checking the file ends with tif \n",
    "        # Read in the image\n",
    "        img = mh.imread(os.path.join(cropped_dir, z))\n",
    "\n",
    "        # Normalize the image\n",
    "        img = img.astype(np.float)\n",
    "        img /= img.max()\n",
    "        img *= 255\n",
    "\n",
    "        # Save the processed image back to the temporary directory\n",
    "        mh.imsave(os.path.join(cropped_dir, z), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69504f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the images in the slices list\n",
    "for z in tqdm(sorted(os.listdir(cropped_dir))):\n",
    "    if (z.endswith(\"tif\")): # checking the file ends with tif \n",
    "        img = mh.imread(os.path.join(cropped_dir, z))\n",
    "    # Apply a Gaussian filter to the image\n",
    "    b = img.copy()\n",
    "    #b = mh.gaussian_filter(b, sigma=3)\n",
    "\n",
    "    # Set values below 100 to 0\n",
    "    b[b < 40] = 0\n",
    "\n",
    "    # Label the regions in the filtered image\n",
    "    labeled, number = mh.label(b)\n",
    "\n",
    "    # filter based on labeled region size\n",
    "    sizes = mh.labeled.labeled_size(labeled)\n",
    "    \n",
    "    print (sizes)\n",
    "\n",
    "    # Remove the regions that are less than 1000\n",
    "    too_small = np.where(sizes < 10)\n",
    "    labeled_only_big = mh.labeled.remove_regions(labeled, too_small)\n",
    "\n",
    "    # Create a binary mask from the filtered labeled regions\n",
    "    binary_mask = labeled_only_big.copy()\n",
    "    binary_mask[binary_mask > 0] = 1\n",
    "    labeled, number_1 = mh.label(binary_mask)\n",
    "    # Apply a Gaussian filter to the closed binary mask\n",
    "    binary_mask_closed_filtered = mh.gaussian_filter(binary_mask_closed, sigma=3)\n",
    "    # Check the number of labeled regions in the final binary mask\n",
    "    labeled, number_final = mh.label(binary_mask_closed_filtered) \n",
    "\n",
    "    # Apply binary threshold to the image to segment the regions of interest\n",
    "    threshold = filters.threshold_otsu(binary_mask_closed_filtered)\n",
    "    binary_image = binary_mask_closed_filtered > threshold\n",
    "\n",
    "    # Label the regions in the binary image\n",
    "    labeled, num_regions = measure.label(binary_image, return_num=True)\n",
    "\n",
    "    # Get the sizes of the labeled regions\n",
    "    region_sizes = measure.regionprops(labeled, intensity_image=binary_mask_closed_filtered)\n",
    "\n",
    "    # Set a threshold for the minimum region size\n",
    "    min_region_size = 5000\n",
    "\n",
    "    # Initialize a variable to count the number of regions above the minimum size\n",
    "    large_regions = 0\n",
    "\n",
    "    # Iterate over the region sizes and count the number of large regions\n",
    "    for region in region_sizes:\n",
    "        if region.area > min_region_size:\n",
    "            large_regions += 1\n",
    "\n",
    "    # Determine if the image has clear segmentation or not\n",
    "\n",
    "    if number_1 <=50 and number_1 >=25:\n",
    "        if large_regions <= 2:\n",
    "            if threshold <= 0.46:\n",
    "                \n",
    "                print(z)\n",
    "                print(\"The image has clear segmentation.\")\n",
    "               # plt.imshow(binary_image)\n",
    "              #  plt.show()\n",
    "                print (number_1, \" <=50 and number_1 >=25 \")\n",
    "                print (threshold, \"<= 0.46\")\n",
    "                print(large_regions, \">= 2\")\n",
    "               # shutil.copy(os.path.join(temp, z), os.path.join(good, z))\n",
    "               # mh.imsave(os.path.join(good, z), binary_image)\n",
    "                print (\"######################################################################\")\n",
    "            else:\n",
    "                print (z)\n",
    "               # plt.imshow(binary_image)\n",
    "               # plt.show()\n",
    "                print (\"image diff -1\")\n",
    "                print (number_1, \" <=50 and number_1 >=25 \")\n",
    "                print (threshold,\"<= 0.46\")\n",
    "                print(large_regions, \">= 2\")\n",
    "                #shutil.copy(os.path.join(temp, z), os.path.join(verybad, z))\n",
    "               # mh.imsave(os.path.join(verybad, z), binary_image)\n",
    "                print (\"######################################################################\")  \n",
    "        else:\n",
    "            print (z)\n",
    "           # plt.imshow(binary_image)\n",
    "           # plt.show()\n",
    "            print (\"image diff -2\")\n",
    "            print (number_1,\" <=50 and number_1 >=25 \")\n",
    "            print (threshold,\"<= 0.46\")\n",
    "            print(large_regions, \">= 2\")\n",
    "            #shutil.move(os.path.join(temp, z), os.path.join(verybad, z))\n",
    "            #mh.imsave(os.path.join(verybad, z), binary_image)\n",
    "            print (\"######################################################################\")    \n",
    "    else:\n",
    "        print (z)\n",
    "       # plt.imshow(binary_image)\n",
    "       # plt.show()\n",
    "        print (\"image diff -3\")\n",
    "        print (number_1, \" <=50 and number_1 >=25 \")\n",
    "        print (threshold, \"<= 0.46\")\n",
    "        print(large_regions, \">= 2\")\n",
    "        #shutil.copy(os.path.join(temp, z), os.path.join(verybad, z))\n",
    "        #mh.imsave(os.path.join(verybad, z), binary_image)\n",
    "        print (\"######################################################################\") \n",
    "else:\n",
    "    print(\"The image has a lot of noise in the segmentation.\")\n",
    "    print (z)\n",
    "   # plt.imshow(binary_image)\n",
    "   # plt.show()\n",
    "    print (number_1, \" <=50 and number_1 >=25 \")\n",
    "    print (threshold, \"<= 0.46\")\n",
    "    print(large_regions, \">= 2\")\n",
    "    #shutil.copy(os.path.join(temp, z), os.path.join(verybad, z))\n",
    "    #mh.imsave(os.path.join(verybad, z), binary_image)    \n",
    "    print (\"######################################################################\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7584d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cropping images in good_original_ for NPY conversion\n",
    "\n",
    "for z in tqdm(sorted(os.listdir(good_images_original))):\n",
    "    if (z.endswith(\"tif\")): # checking the file ends with tif\n",
    "        # Read in the image\n",
    "        img = mh.imread(os.path.join(good_images_original, z))\n",
    "        # Crop the image\n",
    "        img_cropped = img[1500:2012, 2500:3012]\n",
    "            \n",
    "        # Save the processed image back to the temporary directory\n",
    "        mh.imsave(os.path.join(good_images_original, z), img_cropped)\n",
    "        # Add the image to the list\n",
    "        slices.append(img_cropped)\n",
    "        # Display the image\n",
    "        print(z)\n",
    "     #   plt.imshow(img_cropped)\n",
    "     #   plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6edef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(original_dir, mask_dir):\n",
    "    num_images = len([f for f in os.listdir(original_dir) if f.endswith('.tif')])\n",
    "    fig, axs = plt.subplots(num_images, 2, figsize=(5*2, 5*num_images))\n",
    "    for i, z in enumerate(tqdm(sorted(os.listdir(original_dir)))):\n",
    "        if z.endswith(\"tif\"):\n",
    "            # Read in the original image\n",
    "            img_original = plt.imread(os.path.join(original_dir, z))\n",
    "            # Read in the mask image\n",
    "            img_mask = plt.imread(os.path.join(mask_dir, z))\n",
    "            \n",
    "            # Plot the original image on the left\n",
    "            axs[i][0].imshow(img_original)\n",
    "            axs[i][0].set_title(z)\n",
    "            \n",
    "            # Plot the mask image on the right\n",
    "            axs[i][1].imshow(img_mask)\n",
    "            axs[i][0].set_title(z)\n",
    "    \n",
    "   # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c16cbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb43736",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_images(good_images_original,good_images_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2059af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d806b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################STEP-2  Creating NPY files for this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1ace1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can use \n",
    "#f.npyconversion(good_images_original,npy_files + '/original.npy' )\n",
    "#f.npyconversion(good_images_mask, npy_files/mask.npy)\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1041333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def npyconversion(tif_dir, npy_path):\n",
    "    tif_files = [f for f in os.listdir(tif_dir) if f.endswith('.tif')]\n",
    "    data = []\n",
    "    for tif_file in tqdm(tif_files):\n",
    "        img = Image.open(os.path.join(tif_dir, tif_file))\n",
    "        data.append(np.array(img))\n",
    "    np.save(npy_path, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b70ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "npyconversion(good_images_original,npy_files + '/original.npy' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c6973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "npyconversion(good_images_mask, npy_files + '/mask.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb36324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i am cheching using check function to see the files created or not\n",
    "#f.check(npy_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebad0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################step -3 setting up the U-net###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb3db74",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras-unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a691756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras_unet.models import custom_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712fabc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_file = os.path.join(npy_files, 'original.npy')\n",
    "labels_file = os.path.join(npy_files, 'mask.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c666dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load(images_file)\n",
    "labels = np.load(labels_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68111694",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfb1855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full dataset does not have the last channel\n",
    "images = images.reshape(images.shape[0],images.shape[1],images.shape[2],1)\n",
    "labels = labels.reshape(labels.shape[0],labels.shape[1],labels.shape[2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297420b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c495ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.random.permutation(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2283d8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images[p]\n",
    "labels = labels[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f342762",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc746342",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.astype(np.float64)\n",
    "\n",
    "for i in range(images.shape[0]):\n",
    "    images[i] = (images[i] - images[i].min()) / (images[i].max() - images[i].min()) # normalize individually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d25d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a79e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = images[0:50]\n",
    "y_train = labels[0:50]\n",
    "X_val = images[10:20]\n",
    "y_val = labels[10:20]\n",
    "X_test = images[0:]\n",
    "y_test = labels[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d655d20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = custom_unet(\n",
    "    input_shape=(512, 512, 1),\n",
    "    use_batch_norm=False,\n",
    "    num_classes=1,\n",
    "    filters=32,\n",
    "    dropout=0.5,\n",
    "    output_activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509b5258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.optimizers\n",
    "from keras_unet.metrics import iou, iou_thresholded\n",
    "from keras_unet.losses import jaccard_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c25b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6136c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizer_v1.Adam(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93d09ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'Adam',    \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=[iou, iou_thresholded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2b098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    50, \n",
    "                    epochs=500,\n",
    "                    validation_data=(X_val, y_val), \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847076ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_unet.utils import plot_segm_history\n",
    "\n",
    "plot_segm_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89f181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1d5c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_unet.utils import plot_imgs\n",
    "\n",
    "plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred, nm_img_to_plot=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1973bb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(dir):\n",
    "    success = False  # Set default value for success\n",
    "    success_count=0 \n",
    "    for z in tqdm(sorted(os.listdir(dir))):\n",
    "        if (z.endswith(\"tif\")):            \n",
    "            img=mh.imread(os.path.join(dir,z)) \n",
    "            print (z)\n",
    "            a =img.shape\n",
    "            plt.show()\n",
    "            plt.imshow(img)           \n",
    "            success = False            \n",
    "            for a in range(100, 0, -1):\n",
    "                b = img.copy()\n",
    "                b = torch.from_numpy(b)\n",
    "                # Move input data to GPU\n",
    "                b = b.to('cuda')\n",
    "                b.masked_fill_(b < a, 0)               \n",
    "                b_np = b.cpu().numpy()\n",
    "                labeled, number = scipy.ndimage.label(b_np)\n",
    "                labeled = torch.from_numpy(labeled).to(b.device)                 \n",
    "                number = labeled.max().item()                   \n",
    "                sizes = torch.bincount(labeled.view(-1))             \n",
    "                too_small = (sizes < 1500).nonzero(as_tuple=True)[0]\n",
    "                labeled_only_big = labeled.clone()\n",
    "                for i in too_small:\n",
    "                    labeled_only_big[labeled == i] = 0\n",
    "                binary_mask = (labeled_only_big > 0).float()\n",
    "                number_1 = binary_mask.max().item()\n",
    "                kernel_size=3\n",
    "                kernel=torch.ones((kernel_size,kernel_size),device=binary_mask.device)\n",
    "                binary_mask_closed=F.conv2d(binary_mask[None,None,...],kernel[None,None,...],padding=kernel_size//2)>0\n",
    "                binary_mask_closed_filtered=(binary_mask_closed)\n",
    "                binary_mask_closed_filtered = binary_mask_closed_filtered.to(torch.float32)                \n",
    "                binary_mask_closed_filtered_np = binary_mask_closed_filtered.cpu().numpy()               \n",
    "                labeled,number_final= label(binary_mask_closed_filtered_np)                                    \n",
    "                threshold=binary_mask_closed_filtered.flatten().kthvalue(int(binary_mask_closed_filtered.numel()*0.5))[0]                     \n",
    "                binary_image=binary_mask_closed_filtered>threshold              \n",
    "                binary_image_np = binary_image.cpu().numpy()\n",
    "                labeled,num_regions= label(binary_image_np)\n",
    "                region_sizes=[(region==i+1).sum() for i in range(num_regions)]\n",
    "                min_region_size=5000\n",
    "                large_regions_counted=sum([size>min_region_size for size in region_sizes])\n",
    "                for region in region_sizes:\n",
    "                    if region.area > min_region_size:\n",
    "                        large_regions_counted += 1\n",
    "                        print (large_region_counted)\n",
    "                if number_1 <=150 and number_1 >=100:\n",
    "                    if large_regions_counted <=10:\n",
    "                        success=True\n",
    "                        #print(f'success: {success}')\n",
    "                        percent_success=(success_count/len(os.listdir(cropped)))*100\n",
    "                        print(f'percent_success: {percent_success}')\n",
    "                        #print(f'large_regions_counted: {large_regions_counted}')\n",
    "                        print ('number_1')\n",
    "                        break\n",
    "            if success==True:\n",
    "            print (z)                    \n",
    "            success_count+=1        \n",
    "            percent_success=(success_count/len(os.listdir(dir)))*100        \n",
    "            if percent_success>=50 and percent_success<100:\n",
    "                 print('50% Success')                \n",
    "            elif percent_success==100:\n",
    "                 print('100% Success')                    \n",
    "    # Move result back to CPU if needed\n",
    "    result = result.to('cpu')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9601ad84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34d738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = 0  # Define start_time in the global scope\n",
    "\n",
    "def starttime():\n",
    "    global start_time  # Use the global keyword to access the global start_time variable\n",
    "    start_time = time.time()\n",
    "    \n",
    "def endtime():\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"Execution time: {execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bf95e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (5):\n",
    "    starttime()\n",
    "\n",
    "    a = ('Hello world')\n",
    "    print (a)\n",
    "    print ('iteration number',i)\n",
    "    endtime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49458ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pynvml\n",
    "for i in range (5):\n",
    "    pynvml.nvmlInit()\n",
    "\n",
    "    device_count = pynvml.nvmlDeviceGetCount()\n",
    "\n",
    "    for i in range(device_count):\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n",
    "        name = pynvml.nvmlDeviceGetName(handle)\n",
    "        serial = pynvml.nvmlDeviceGetSerial(handle)\n",
    "        util = pynvml.nvmlDeviceGetUtilizationRates(handle)\n",
    "        timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "        print(f\"{name} - {serial} - Utilization: {util.gpu}% - Timestamp: {timestamp}\")\n",
    "\n",
    "    pynvml.nvmlShutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935629f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = sorted([os.path.join(s,z) for z in os.listdir(s) if z.endswith(\"tif\")])\n",
    "for i in range(2):\n",
    "            img=mh.imread(image_files[i])\n",
    "            print (i)\n",
    "            name_only = os.path.basename(image_files[i])\n",
    "            print (\"this iteration is with g value\",i,\"for the image :\",name_only)\n",
    "            #print(name_only)\n",
    "            plt.imshow(img)\n",
    "            plt.show() \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d37d341",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
