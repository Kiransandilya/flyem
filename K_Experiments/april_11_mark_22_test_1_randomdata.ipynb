{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "964e0a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## CPU  BASED ITERATION SEGMENTATION USING TRADITIONAL COMPUTER VISION ##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21b8002c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /home/kiran.sandilya001/miniconda3/envs/O/lib/python3.9/site-packages (9.0.1)\n",
      "Requirement already satisfied: tabulate in /home/kiran.sandilya001/miniconda3/envs/O/lib/python3.9/site-packages (0.9.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow\n",
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e2f1e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNISNSTALL EXISTING NUMPY MAHATOS AND RE-INSALL IT BEFORE RUNNING THIS ?make sure you have a numpy1.24 or above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba805373",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip uninstall numpy mahotas -y     ## run this two times just to make sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7d2a7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall numpy mahotas -y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5fcb7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy mahotas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e5ea222",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xf but this version of numpy is 0xd",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xd"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not import submodules (exact error was: numpy.core.multiarray failed to import).\n",
      "\n",
      "There are many reasons for this error the most common one is that you have\n",
      "either not built the packages or have built (using `python setup.py build`) or\n",
      "installed them (using `python setup.py install`) and then proceeded to test\n",
      "mahotas-imread **without changing the current directory**.\n",
      "\n",
      "Try installing and then changing to another directory before importing mahotas.\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xf but this version of numpy is 0xd",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xd"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import shutil\n",
    "import random\n",
    "import inspect\n",
    "#import imageio as im\n",
    "import numpy as np\n",
    "import mahotas as mh\n",
    "from PIL import Image\n",
    "from tabulate import tabulate\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "#from skimage import measure, filters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e3697d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "604a46b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade mahotas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c415029",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### EXCEPT FOR RAW DATA I ALWAYS USE FRESH DIRECTORIES #############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4b17599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original directory path and working directory path for images\n",
    "data = \"/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir/raw_files\"\n",
    "working_dir = \"/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir\"\n",
    "new_data ='/raid/mpsych/RISTERLAB/cs410_raw_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be946bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### THE BELOW ARE TEST DIRECTORIES THEY CHANGE BASED ON TESTS  #########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "229dd806",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"test4\" # you can change this according to your needs. to access that data.\n",
    "#current experiments are in test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "934be3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "real = f\"{working_dir}/{experiment}/real_images\"\n",
    "#########################################################################################################\n",
    "\n",
    "directories = {\n",
    "    \"normalized\": f\"{working_dir}/{experiment}/normalized_images\",\n",
    "    \"cropped\": f\"{working_dir}/{experiment}/cropped_images\",\n",
    "    \"pre_processing\": f\"{working_dir}/{experiment}/pre_processing\",\n",
    "    \"npy\": f\"{working_dir}/{experiment}/pre_processing/npy\",\n",
    "    \"originals\": f\"{working_dir}/{experiment}/pre_processing/originals\",\n",
    "    \"masks\": f\"{working_dir}/{experiment}/pre_processing/masks\",\n",
    "    \"test\": f\"{working_dir}/{experiment}/pre_processing/test\",\n",
    "    \n",
    "    \"s\": f\"{working_dir}/{experiment}/S\",\n",
    "    \"crop_original\": f\"{working_dir}/{experiment}/pre_processing/crop_originals\",\n",
    "    \"crop_masks\": f\"{working_dir}/{experiment}/pre_processing/crop_masks\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc40d072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55c159d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################functions\n",
    "start_time = 0  # Define start_time in the global scope\n",
    "\n",
    "def starttime():\n",
    "    global start_time  # Use the global keyword to access the global start_time variable\n",
    "    start_time = time.time()\n",
    "    #hint: starttime() - To start timer.\n",
    "    \n",
    "def endtime():\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"Execution time: {execution_time:.2f} seconds\")\n",
    "    #hint: endtime() - To end timer\n",
    "\n",
    "def check(path):\n",
    "    # Create the directory if it does not exist\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    # Remove the directory and all its contents\n",
    "    shutil.rmtree(path)\n",
    "\n",
    "    # Create a new empty directory\n",
    "    os.mkdir(path)\n",
    "    #hint: check(path) - To recreate a particular path\n",
    "            \n",
    "def heavycrop(test):\n",
    "    starttime()\n",
    "    for z in tqdm(sorted(os.listdir(test))):\n",
    "        if z.endswith(\"tif\"):\n",
    "            # Read in the image\n",
    "            img = mh.imread(os.path.join(test, z))\n",
    "\n",
    "            # Calculate the number of crops in each dimension\n",
    "            height, width = img.shape[:2]\n",
    "            num_crops_y = height // 512\n",
    "            num_crops_x = width // 512\n",
    "\n",
    "            for i in range(num_crops_y):\n",
    "                for j in range(num_crops_x):\n",
    "                    # Crop the image\n",
    "                    start_y = i * 512\n",
    "                    start_x = j * 512\n",
    "                    img_cropped = img[start_y:start_y+512, start_x:start_x+512]\n",
    "\n",
    "                    # Create a new file name for the cropped image\n",
    "                    file_name, file_ext = os.path.splitext(z)\n",
    "                    new_file_name = f\"{file_name}_{i}_{j}{file_ext}\"\n",
    "\n",
    "                    # Save only if cropped image has shape (512, 512)\n",
    "                    if img_cropped.shape == (512, 512):\n",
    "                        mh.imsave(os.path.join(test, new_file_name), img_cropped)\n",
    "                    else:\n",
    "                        print(f\"Warning: Cropped image has unexpected shape {img_cropped.shape}\")\n",
    "                        \n",
    "            endtime()\n",
    "            # Remove original image file after cropping is done.\n",
    "            os.remove(os.path.join(test,z))\n",
    "            #hint: heavycrop(spath) - To heavy crop all images 512x512\n",
    "            \n",
    "def npyconversion(tif_dir, npy_path):\n",
    "    tif_files = [f for f in os.listdir(tif_dir) if f.endswith('.tif')]\n",
    "    tif_files.sort()\n",
    "    data = []\n",
    "    for tif_file in tqdm(tif_files):\n",
    "        img = Image.open(os.path.join(tif_dir, tif_file))\n",
    "        data.append(np.array(img))\n",
    "    np.save(npy_path, data)\n",
    "    #hint: npyconversion(path , npy + '/filename.npy' ) -To create NPY files\n",
    "            \n",
    "def a2bcopy(path1, path2):\n",
    "    for z in tqdm(sorted(os.listdir(path1))):\n",
    "        if z.endswith(\"tif\"):\n",
    "            shutil.copy(os.path.join(path1, z), os.path.join(path2, z))\n",
    "            #hint: a2bcopy(sorce path, dest path) - To copy all images\n",
    "            \n",
    "def crop(test):\n",
    "    for z in tqdm(sorted(os.listdir(test))):\n",
    "        if (z.endswith(\"tif\")): # checking the file ends with tif\n",
    "            # Read in the image\n",
    "            img = mh.imread(os.path.join(test, z))\n",
    "            img_cropped = img[1000:2500, 2500:4500]\n",
    "            mh.imsave(os.path.join(test, z), img_cropped)\n",
    "            print(z)\n",
    "            #hint: crop(spath) - To crop all images\n",
    "    \n",
    "def a2brandom(src_dir, dst_dir, number):\n",
    "    # Get a list of all image files in the source directory\n",
    "    image_files = [f for f in tqdm(os.listdir(src_dir)) if f.endswith('.tif')]\n",
    "    # Randomly select 10 images from the list\n",
    "    selected_images = random.sample(image_files, number)\n",
    "    # Copy the selected images to the destination directory\n",
    "    for image in selected_images:\n",
    "        src_path = os.path.join(src_dir, image)\n",
    "        dst_path = os.path.join(dst_dir, image)\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "    # Print a message when done\n",
    "    print('Copied 10 random images to', dst_dir)\n",
    "    #hint: a2brandom(sorce path, dest path, random number) - To copy n random images\n",
    "    \n",
    "def count_files(dir_path):\n",
    "    if os.path.isdir(dir_path):\n",
    "        file_count = 0\n",
    "        for file_name in os.listdir(dir_path):\n",
    "            file_path = os.path.join(dir_path, file_name)\n",
    "            file_size_bytes = os.path.getsize(file_path)\n",
    "            file_size_mb = round(file_size_bytes / (1024 * 1024), 2)\n",
    "            #print(f'{file_name} - Size: {file_size_mb} MB')\n",
    "            file_count += 1\n",
    "        return file_count\n",
    "    else:\n",
    "        print(f\"{dir_path} is not a valid directory\")\n",
    "        return 0    \n",
    "        #hint: count_files(path) - To count number of files in that path\n",
    "    \n",
    "def norm(path):\n",
    "    for z in tqdm(sorted(os.listdir(path))):# added interactive progressbar to decrease the uncertanity and to increase curiosity :)\n",
    "        if (z.endswith(\"tif\")): # checking the file ends with tif \n",
    "            img = mh.imread(os.path.join(path, z))            \n",
    "            # Normalize the image\n",
    "            img = img.astype(np.float64)\n",
    "            img /= img.max()\n",
    "            img *= 255            \n",
    "            # Save the processed image back to the temporary directory\n",
    "            mh.imsave(os.path.join(path, z), img)\n",
    "            #hint: norm(path) - To normalize all the images in the path\n",
    "            \n",
    "def shape(raw):\n",
    "    for z in tqdm(sorted(os.listdir(raw))):\n",
    "        if (z.endswith(\"tif\")):\n",
    "            img = mh.imread(os.path.join(raw, z))\n",
    "            print (img.shape)\n",
    "            #hint: shape(path) _ To print shape of all the images in the path\n",
    "            \n",
    "def refresh(experiment: str, directories: dict):\n",
    "    for key in directories:\n",
    "        if os.path.exists(directories[key]):\n",
    "            shutil.rmtree(directories[key])\n",
    "        os.makedirs(directories[key])\n",
    "        #hint: refresh(\"experiment name\", directories) - to recreate all directories in that dict\n",
    "        \n",
    "def paths(directories):\n",
    "    for key, value in directories.items():\n",
    "        globals()[key] = value\n",
    "    return directories\n",
    "    #hint: paths(directories) - To call the directories outside the dictionary\n",
    "        \n",
    "def help():\n",
    "    functions = [value for key, value in globals().items() if inspect.isfunction(value)]\n",
    "    headers = [\"Function\", \"Hint\", \"Used for\"]\n",
    "    data = []\n",
    "    for func in functions:\n",
    "        source = inspect.getsource(func)\n",
    "        lines = source.split(\"\\n\")\n",
    "        hint_line = [line for line in lines if line.strip().startswith(\"#hint:\")]\n",
    "        if hint_line:\n",
    "            hint_parts = hint_line[0].split(\"#hint:\")[1].strip().split(\" - \")\n",
    "            hint_text = hint_parts[0]\n",
    "            usage_text = hint_parts[1] if len(hint_parts) > 1 else \"\"\n",
    "            data.append([f\"{func.__name__}()\", hint_text, usage_text])\n",
    "    print(tabulate(data, headers=headers))\n",
    "    \n",
    "def readpaths(directories):\n",
    "    for key, path in directories.items():\n",
    "        globals()[key] = path\n",
    "            \n",
    "            \n",
    "#def del(path):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24cf163a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'normalized': '/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir/test4/normalized_images',\n",
       " 'cropped': '/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir/test4/cropped_images',\n",
       " 'pre_processing': '/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir/test4/pre_processing',\n",
       " 'npy': '/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir/test4/pre_processing/npy',\n",
       " 'originals': '/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir/test4/pre_processing/originals',\n",
       " 'masks': '/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir/test4/pre_processing/masks',\n",
       " 'test': '/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir/test4/pre_processing/test',\n",
       " 's': '/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir/test4/S',\n",
       " 'crop_original': '/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir/test4/pre_processing/crop_originals',\n",
       " 'crop_masks': '/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir/test4/pre_processing/crop_masks'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths(directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ab5c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "100b6970",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function         Hint                                                               Used for\n",
      "---------------  -----------------------------------------------------------------  ----------------------------------------------\n",
      "starttime()      starttime()                                                        To start timer.\n",
      "endtime()        endtime()                                                          To end timer\n",
      "check()          check(path)                                                        To recreate a particular path\n",
      "heavycrop()      heavycrop(spath)                                                   To heavy crop all images 512x512\n",
      "npyconversion()  npyconversion(path , npy + '/filename.npy' ) -To create NPY files\n",
      "a2bcopy()        a2bcopy(sorce path, dest path)                                     To copy all images\n",
      "crop()           crop(spath)                                                        To crop all images\n",
      "a2brandom()      a2brandom(sorce path, dest path, random number)                    To copy n random images\n",
      "count_files()    count_files(path)                                                  To count number of files in that path\n",
      "norm()           norm(path)                                                         To normalize all the images in the path\n",
      "shape()          shape(path) _ To print shape of all the images in the path\n",
      "refresh()        refresh(\"experiment name\", directories)                            to recreate all directories in that dict\n",
      "paths()          paths(directories)                                                 To call the directories outside the dictionary\n"
     ]
    }
   ],
   "source": [
    "help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b62bee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## The below are manual functions to delete any particular directory and create it again. ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81f20171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check(real)\n",
    "# check(pre_processing)\n",
    "# check(normalized)\n",
    "# check(cropped)\n",
    "\n",
    "# check(crop_original)\n",
    "# check(crop_masks)\n",
    "# check(npy)\n",
    "# check(originals)\n",
    "# check(masks)\n",
    "# check(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b6ada03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MANUALLY CHECK THAT ALL FOLDERS ARE AVAILABLE AND EMPTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aca6b39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "readpaths(directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfd8454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####################      Getting some random data                ###############################\n",
    "# raw = '/raid/mpsych/backups/flyem/WildTypeCS1/Raw/VSOverviewTileSet/Acquired'\n",
    "# raw1 = '/raid/mpsych/backups/flyem/WildTypeCS2/incoming/VSOverviewTileSet/Acquired'\n",
    "# raw2 ='/raid/mpsych/backups/flyem/NINA_D1_MUTANT/VSOverviewTileSet/Acquired'\n",
    "# raw3 = '/raid/mpsych/backups/flyem/MPSDel/VSOverviewTileSet/Acquired'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83145d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_files(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b128b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_files(raw1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f4c819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_files(raw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "638971b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_files(raw3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a728707",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a2brandom(raw,new_data,800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5cd35be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_files(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d391fe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a2brandom(raw1,new_data,1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c299af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_files(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4757fc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a2brandom(raw2,new_data,2100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd535587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_files(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ca306d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a2brandom(raw3,new_data,1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4edcfcc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2152"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_files(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2e9060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4adf72da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a2brandom(raw,new_data,800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02d56986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a2brandom(raw1,data,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48dbb241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_files(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d09a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a2bcopy(new_data,real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ddafac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a2bcopy(new_data,normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "11163738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a2bcopy(new_data,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6fe2cb15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a2bcopy(new_data,cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2f64ef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_files(cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23d4bf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############FINISHED COPYING FILES TO DIRECTORIES, NOW Normalization, cropping, segmentation ##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d24b8450",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb6bcf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bf6fe741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm(cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d8a33a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c5133ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4efb7bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop(cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ed408902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20a6b35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "876663df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heavycrop(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3e788900",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!lspci | grep -i nvidia\n",
    "# TO check the graphic card availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b67681a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_files(cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e8f23eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################    SEGMENTATION BEGIN    #########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "039cb189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import mahotas as mh\n",
    "from skimage import measure, filters\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8a1810",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                          | 0/2152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000000_000000_000000_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_127558/3386246936.py:50: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(10,10))\n",
      "  0%|                                                                                                                                               | 1/2152 [00:47<28:22:06, 47.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000000_000000.tif is:\n",
      "Execution time: 47.43 seconds\n",
      "000000_000000_000001_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▏                                                                                                                                              | 2/2152 [02:06<39:27:24, 66.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000001_000000.tif is:\n",
      "Execution time: 79.04 seconds\n",
      "000000_000000_000002_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▏                                                                                                                                              | 3/2152 [03:26<43:12:34, 72.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000002_000000.tif is:\n",
      "Execution time: 79.87 seconds\n",
      "000000_000000_000003_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▎                                                                                                                                              | 4/2152 [04:47<45:16:10, 75.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000003_000000.tif is:\n",
      "Execution time: 81.18 seconds\n",
      "000000_000000_000004_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▎                                                                                                                                              | 5/2152 [06:09<46:32:05, 78.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000004_000000.tif is:\n",
      "Execution time: 81.81 seconds\n",
      "000000_000000_000005_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▍                                                                                                                                              | 6/2152 [07:31<47:19:26, 79.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000005_000000.tif is:\n",
      "Execution time: 81.99 seconds\n",
      "000000_000000_000006_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▍                                                                                                                                              | 7/2152 [08:25<42:16:15, 70.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000006_000000.tif is:\n",
      "Execution time: 53.52 seconds\n",
      "000000_000000_000007_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▌                                                                                                                                              | 8/2152 [09:47<44:23:15, 74.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000007_000000.tif is:\n",
      "Execution time: 82.18 seconds\n",
      "000000_000000_000008_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▌                                                                                                                                              | 9/2152 [10:41<40:29:30, 68.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000008_000000.tif is:\n",
      "Execution time: 53.67 seconds\n",
      "000000_000000_000009_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▋                                                                                                                                             | 10/2152 [12:03<43:07:53, 72.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000009_000000.tif is:\n",
      "Execution time: 82.46 seconds\n",
      "000000_000000_000010_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▋                                                                                                                                             | 11/2152 [13:26<44:56:09, 75.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000010_000000.tif is:\n",
      "Execution time: 82.48 seconds\n",
      "000000_000000_000011_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▊                                                                                                                                             | 12/2152 [14:47<46:01:40, 77.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000011_000000.tif is:\n",
      "Execution time: 81.67 seconds\n",
      "000000_000000_000012_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▊                                                                                                                                             | 13/2152 [16:10<46:54:13, 78.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000012_000000.tif is:\n",
      "Execution time: 82.38 seconds\n",
      "000000_000000_000013_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▉                                                                                                                                             | 14/2152 [17:31<47:22:44, 79.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000013_000000.tif is:\n",
      "Execution time: 81.68 seconds\n",
      "000000_000000_000014_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▉                                                                                                                                             | 15/2152 [18:53<47:43:25, 80.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000014_000000.tif is:\n",
      "Execution time: 81.79 seconds\n",
      "000000_000000_000015_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|█                                                                                                                                             | 16/2152 [20:13<47:39:52, 80.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000015_000000.tif is:\n",
      "Execution time: 80.15 seconds\n",
      "000000_000000_000016_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|█                                                                                                                                             | 17/2152 [21:34<47:36:40, 80.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000016_000000.tif is:\n",
      "Execution time: 80.12 seconds\n",
      "000000_000000_000017_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|█▏                                                                                                                                            | 18/2152 [22:52<47:13:02, 79.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000017_000000.tif is:\n",
      "Execution time: 78.16 seconds\n",
      "000000_000000_000018_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|█▎                                                                                                                                            | 19/2152 [24:11<47:11:12, 79.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000018_000000.tif is:\n",
      "Execution time: 79.57 seconds\n",
      "000000_000000_000019_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|█▎                                                                                                                                            | 20/2152 [25:29<46:52:34, 79.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000019_000000.tif is:\n",
      "Execution time: 77.98 seconds\n",
      "000000_000000_000020_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|█▍                                                                                                                                            | 21/2152 [26:48<46:41:19, 78.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000020_000000.tif is:\n",
      "Execution time: 78.18 seconds\n",
      "000000_000000_000021_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|█▍                                                                                                                                            | 22/2152 [28:03<46:08:13, 77.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000021_000000.tif is:\n",
      "Execution time: 75.85 seconds\n",
      "000000_000000_000022_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|█▌                                                                                                                                            | 23/2152 [29:18<45:29:48, 76.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000022_000000.tif is:\n",
      "Execution time: 74.46 seconds\n",
      "000000_000000_000023_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|█▌                                                                                                                                            | 24/2152 [30:33<45:10:44, 76.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000023_000000.tif is:\n",
      "Execution time: 75.23 seconds\n",
      "000000_000000_000024_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|█▋                                                                                                                                            | 25/2152 [31:49<45:07:33, 76.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000024_000000.tif is:\n",
      "Execution time: 76.21 seconds\n",
      "000000_000000_000025_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|█▋                                                                                                                                            | 26/2152 [33:05<44:52:18, 75.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000025_000000.tif is:\n",
      "Execution time: 75.02 seconds\n",
      "000000_000000_000026_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|█▊                                                                                                                                            | 27/2152 [34:20<44:49:37, 75.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000026_000000.tif is:\n",
      "Execution time: 75.81 seconds\n",
      "000000_000000_000027_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|█▊                                                                                                                                            | 28/2152 [35:35<44:33:48, 75.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000027_000000.tif is:\n",
      "Execution time: 74.54 seconds\n",
      "000000_000000_000028_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|█▉                                                                                                                                            | 29/2152 [36:51<44:32:48, 75.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000028_000000.tif is:\n",
      "Execution time: 75.52 seconds\n",
      "000000_000000_000029_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|█▉                                                                                                                                            | 30/2152 [38:06<44:25:45, 75.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000029_000000.tif is:\n",
      "Execution time: 74.96 seconds\n",
      "000000_000000_000030_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|██                                                                                                                                            | 31/2152 [39:21<44:29:21, 75.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000030_000000.tif is:\n",
      "Execution time: 75.80 seconds\n",
      "000000_000000_000031_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|██                                                                                                                                            | 32/2152 [40:36<44:17:13, 75.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000031_000000.tif is:\n",
      "Execution time: 74.45 seconds\n",
      "000000_000000_000032_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|██▏                                                                                                                                           | 33/2152 [41:50<44:08:28, 74.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000032_000000.tif is:\n",
      "Execution time: 74.46 seconds\n",
      "000000_000000_000033_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|██▏                                                                                                                                           | 34/2152 [43:05<44:06:00, 74.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000033_000000.tif is:\n",
      "Execution time: 74.84 seconds\n",
      "000000_000000_000034_000000.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|██▎                                                                                                                                           | 35/2152 [44:20<44:07:16, 75.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for iteration 1 image 000000_000000_000034_000000.tif is:\n",
      "Execution time: 75.16 seconds\n",
      "000000_000000_000035_000000.tif\n"
     ]
    }
   ],
   "source": [
    "success_count=0 \n",
    "for z in tqdm(sorted(os.listdir(cropped))):\n",
    "    if (z.endswith(\"tif\")): # checking the file ends with tif \n",
    "        img = mh.imread(os.path.join(cropped, z))\n",
    "        print (z)\n",
    "        #plt.imshow(img)\n",
    "        #plt.show()\n",
    "    \n",
    "        # Apply a Gaussian filter to the image\n",
    "        c = img.copy()\n",
    "        #b = mh.gaussian_filter(b, sigma=3)\n",
    "\n",
    "        # Set values below 100 to 0\n",
    "        starttime()\n",
    "        for a in range(150, 0, -1):\n",
    "           # starttime()\n",
    "            b= img.copy()\n",
    "            b = mh.gaussian_filter(b, sigma=3)\n",
    "            b[b < a] = 0\n",
    "            #print (a)      \n",
    "            #b = exposure.equalize_hist(b)\n",
    "            # Label the regions in the filtered image\n",
    "            labeled, number = mh.label(b)\n",
    "\n",
    "\n",
    "            # filter based on labeled region size\n",
    "            sizes = mh.labeled.labeled_size(labeled)\n",
    "\n",
    "            # Remove the regions that are less than 1000\n",
    "            too_small = np.where(sizes < 1500)\n",
    "            labeled_only_big = mh.labeled.remove_regions(labeled, too_small)\n",
    "\n",
    "            #too_large = np.where(sizes > 20500)\n",
    "            #labeled_only_big = mh.labeled.remove_regions(labeled, too_large)\n",
    "            #for debug\n",
    "            #plt.imshow(labeled_only_big)\n",
    "            #plt.show()\n",
    "\n",
    "\n",
    "            # Create a binary mask from the filtered labeled regions\n",
    "            binary_mask = labeled_only_big.copy()\n",
    "            binary_mask[binary_mask > 0] = 1\n",
    "            labeled, number_1 = mh.label(binary_mask)\n",
    "\n",
    "\n",
    "             # Close the regions in the binary mask\n",
    "            binary_mask_closed = mh.morph.close(binary_mask)\n",
    "            \n",
    "            \n",
    "            plt.figure(figsize=(10,10))\n",
    "            #plt.imshow(binary_mask_closed)\n",
    "            #plt.show() \n",
    "            \n",
    "            # Set a threshold for the minimum region size           \n",
    "            min_region_size = 3000\n",
    "            \n",
    "            # Initialize a variable to count the number of regions above the minimum size\n",
    "            large_regions = 0\n",
    "\n",
    "            # Get the sizes of the labeled regions\n",
    "            region_sizes = measure.regionprops(labeled, intensity_image=binary_mask_closed)\n",
    "\n",
    "            # Iterate over the region sizes and count the number of large regions\n",
    "            for region in region_sizes:\n",
    "                if region.area > min_region_size:\n",
    "                     large_regions += 1\n",
    "\n",
    "\n",
    "            threshold = filters.threshold_otsu(binary_mask_closed) \n",
    "            binary_image = binary_mask_closed > threshold\n",
    "#             print('time taken for iteration',a,'image',z ,'is:')\n",
    "#             endtime()\n",
    "#             if number_1>= 90:                \n",
    "#                 print (z)\n",
    "#                 plt.imshow(binary_image)\n",
    "#                 plt.show()\n",
    "#                 print (number_1)\n",
    "#                 print (threshold)\n",
    "#                 print(large_regions)\n",
    "                  \n",
    "            if number_1 <=150 and number_1 >=100:\n",
    "                if large_regions <=20:       # 20 is ideal value \n",
    "                    print (\"######################################################################\")\n",
    "                    print(z)\n",
    "                    #plt.figure(figsize=(10,10))\n",
    "                    print(\"The image has clear segmentation.\")\n",
    "                    #plt.imshow(binary_image)\n",
    "                    #plt.show()\n",
    "                    print (number_1)\n",
    "                    print (threshold)\n",
    "                    print(large_regions)\n",
    "                    shutil.move(os.path.join(normalized,z),os.path.join(originals,z))                 \n",
    "                    shutil.move(os.path.join(cropped,z),os.path.join(masks,z))                 \n",
    "                    mh.imsave(os.path.join(masks,z),binary_image)                 \n",
    "                    #print (sizes)\n",
    "                    print (\"######################################################################\")\n",
    "                    success_count+=1\n",
    "                    print (success_count)\n",
    "                    break\n",
    "        print('time taken for iteration',a,'image',z ,'is:')\n",
    "        endtime()\n",
    "print (success_count)\n",
    "print ('######################################### DONE        ############################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61008f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the files which got segemented well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62817614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# origi = int(count_files(masks))\n",
    "# croppi = int(count_files(real))\n",
    "# seg_well =(((origi)/(croppi))*100) \n",
    "# print (\"percentage = \",seg_well ,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551bb73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_files(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075cb5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (\"sucessfilly segemented\", origi,\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ca235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################   SEGMENTATION END   ################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef25870",
   "metadata": {},
   "outputs": [],
   "source": [
    "######copying data for heavycropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e56c9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a2bcopy(masks,crop_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116cc5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a2bcopy(originals,crop_originals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130da0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#heavycrop(crop_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcde6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#heavycrop(crop_originals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc8e57e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8884b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_files(crop_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46236cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_files(crop_originals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e558cbae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50391435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# npyconversion(crop_originals, npy + '/original.npy' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba08853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# npyconversion(crop_masks, npy + '/mask.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedb25dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#npyconversion(test, npy + '/test.npy' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ece825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_files(npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f37e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### run this command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c3162c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy==1.19.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8357714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################  KERAS  #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb3db74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras-unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150a1f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import shutil\n",
    "import random\n",
    "import inspect\n",
    "#import imageio as im\n",
    "import numpy as np\n",
    "import mahotas as mh\n",
    "from PIL import Image\n",
    "from tabulate import tabulate\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "#from skimage import measure, filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef84d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original directory path and working directory path for images\n",
    "data = \"/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir/raw_files\"\n",
    "working_dir = \"/raid/mpsych/RISTERLAB/fly_segmentation_experiments/data_dir\"\n",
    "######################################################################################################\n",
    "experiment = \"test2\" \n",
    "######################################################################################################\n",
    "real = f\"{working_dir}/{experiment}/real_images\"\n",
    "#########################################################################################################\n",
    "\n",
    "directories = {\n",
    "    \"normalized\": f\"{working_dir}/{experiment}/normalized_images\",\n",
    "    \"cropped\": f\"{working_dir}/{experiment}/cropped_images\",\n",
    "    \"npy\": f\"{working_dir}/{experiment}/pre_processing/npy\",\n",
    "    \"originals\": f\"{working_dir}/{experiment}/pre_processing/originals\",\n",
    "    \"masks\": f\"{working_dir}/{experiment}/pre_processing/masks\",\n",
    "    \"test\": f\"{working_dir}/{experiment}/pre_processing/test\",\n",
    "    \"s\": f\"{working_dir}/{experiment}/S\",\n",
    "    \"crop_original\": f\"{working_dir}/{experiment}/pre_processing/crop_originals\",\n",
    "    \"crop_masks\": f\"{working_dir}/{experiment}/pre_processing/crop_masks\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a691756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras_unet.models import custom_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4884f7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "npy = f\"{working_dir}/{experiment}/pre_processing/npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712fabc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_file = os.path.join(npy, 'original.npy')\n",
    "labels_file = os.path.join(npy, 'mask.npy')\n",
    "#test_files = os.path.join(npy, 'test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c666dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load(images_file)\n",
    "labels = np.load(labels_file)\n",
    "#test = np.load(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68111694",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfb1855",
   "metadata": {},
   "outputs": [],
   "source": [
    " # full dataset does not have the last channel\n",
    "images = images.reshape(images.shape[0],images.shape[1],images.shape[2],1)\n",
    "labels = labels.reshape(labels.shape[0],labels.shape[1],labels.shape[2],1)\n",
    "#test = test.reshape(test.shape[0],test.shape[1],test.shape[2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297420b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c495ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.random.permutation(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2283d8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images[p]\n",
    "labels = labels[p]\n",
    "#test = test[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f342762",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc746342",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.astype(np.float64)\n",
    "for i in range(images.shape[0]):\n",
    "    images[i] = (images[i] - images[i].min()) / (images[i].max() - images[i].min()) # normalize individually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d25d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a79e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = images[0:1200]\n",
    "y_train = labels[0:1200]\n",
    "X_val = images[1201:1700]\n",
    "y_val = labels[1201:1700]\n",
    "X_test = images[1701:1812]\n",
    "y_test = labels[1701:1812]\n",
    "\n",
    "#X_test = test[80:]\n",
    "#y_test = test[80:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d655d20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = custom_unet(\n",
    "    input_shape=(512, 512, 1),\n",
    "    use_batch_norm=False,\n",
    "    num_classes=1,\n",
    "    filters=32,\n",
    "    dropout=0.5,\n",
    "    output_activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509b5258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.optimizers\n",
    "from keras_unet.metrics import iou, iou_thresholded\n",
    "from keras_unet.losses import jaccard_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c25b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6136c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizer_v1.Adam(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93d09ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'Adam',    \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=[iou, iou_thresholded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af38a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!du -h --max-depth=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6b24cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### batch size 50 , epochs =1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113f685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(batch,epochs):\n",
    "    print (\"training and prediction for\",\"batch size:  \",batch, \"epochs:  \", epochs)\n",
    "    history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    batch, \n",
    "                    epochs=epochs,\n",
    "                    validation_data=(X_val, y_val), \n",
    "                    verbose=1)\n",
    "    \n",
    "    from keras_unet.utils import plot_segm_history\n",
    "\n",
    "    plot_segm_history(history)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    from keras_unet.utils import plot_imgs\n",
    "\n",
    "    plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred, nm_img_to_plot=100)# number to plot also need to e defined in function\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfa0ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import regularizers\n",
    "# from keras.layers import Dense\n",
    "# from keras.callbacks import EarlyStopping\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras_unet.utils import plot_segm_history, plot_imgs\n",
    "\n",
    "# def training(batch, epochs):\n",
    "#     print(\"training and prediction for\", \"batch size: \", batch, \"epochs: \", epochs)\n",
    "\n",
    "# #     # Regularization\n",
    "#     layer = Dense(units=64,\n",
    "#                   kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01),\n",
    "#                   bias_regularizer=regularizers.l2(0.01))\n",
    "\n",
    "    # Early stopping\n",
    "    #early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "#     # Data augmentation\n",
    "#     datagen = ImageDataGenerator(rotation_range=20,\n",
    "#                                  width_shift_range=0.2,\n",
    "#                                  height_shift_range=0.2,\n",
    "#                                  horizontal_flip=True)\n",
    "#     datagen.fit(X_train)\n",
    "\n",
    "#     # Training with data augmentation\n",
    "#     history = model.fit(datagen.flow(X_train, y_train, batch_size=batch),\n",
    "#                         steps_per_epoch=len(X_train) / batch,\n",
    "#                         epochs=epochs,\n",
    "#                         validation_data=(X_val, y_val),\n",
    "#                         callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "########################################ONLY EARLY STOPPING###################################\n",
    "#     # Early stopping\n",
    "#     early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "#     # Training with early stopping\n",
    "#     history = model.fit(X_train,\n",
    "#                         y_train,\n",
    "#                         batch_size=batch,\n",
    "#                         epochs=epochs,\n",
    "#                         validation_data=(X_val, y_val),\n",
    "#                         callbacks=[early_stopping])\n",
    "\n",
    "#     # Plotting results\n",
    "#     plot_segm_history(history)\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred, nm_img_to_plot=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0002b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_unet.utils import plot_segm_history, plot_imgs\n",
    "\n",
    "def trainingearlystopping(batch, epochs):\n",
    "    print(\"training and prediction for\", \"batch size: \", batch, \"epochs: \", epochs)\n",
    "########################################ONLY EARLY STOPPING###################################\n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "    # Training with early stopping\n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        batch_size=batch,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        callbacks=[early_stopping])\n",
    "\n",
    "    # Plotting results\n",
    "    plot_segm_history(history)\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Apply thresholding\n",
    "    threshold = 0.2\n",
    "    y_pred_binary = (y_pred > threshold).astype(np.uint8)\n",
    "    plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred, nm_img_to_plot=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9145fc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingearlystopping(60,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6358db50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainingearlystopping(60,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff79002",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainingearlystopping(60,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11feebf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ TRYING THRESHOLD VALUES\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def trainingwiththres(batch, epochs, thresholds, n_images):\n",
    "    print(\"training and prediction for\", \"batch size: \", batch, \"epochs: \", epochs)\n",
    "\n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "    # Training with early stopping\n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        batch_size=batch,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        callbacks=[early_stopping])\n",
    "\n",
    "    # Plotting results\n",
    "    plot_segm_history(history)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Apply multiple thresholds\n",
    "    y_pred_binaries = []\n",
    "    for threshold in thresholds:\n",
    "        y_pred_binary = (y_pred > threshold).astype(np.uint8)\n",
    "        y_pred_binaries.append(y_pred_binary)\n",
    "\n",
    "    # Plot binary masks for multiple thresholds\n",
    "    fig, axes = plt.subplots(n_images, len(thresholds), figsize=(15, 15))\n",
    "    for i in range(n_images):\n",
    "        for j in range(len(thresholds)):\n",
    "            axes[i][j].imshow(y_pred_binaries[j][i])\n",
    "            axes[i][j].set_title(f'Threshold {thresholds[j]}')\n",
    "            axes[i][j].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e72ae8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "thresholds = [0.2, 0.4, 0.6, 0.8]\n",
    "n_images = 10\n",
    "history = trainingwiththres(60, 100, thresholds, n_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58aefbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db0559b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcbf20f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d802ccd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fcb3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c30a50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f8c72c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e52631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba311bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967e9a45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a04400e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b077b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#training(60,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46d5fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# a little overlifting has been noticed in the above graph so we are using new techiniques to decrease that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c589d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training(60,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31ebb9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cab8945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7470ba18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c658588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7fdf01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9c72b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84af0363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc49fda0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f13d9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0972bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2de846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603eeb77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d343dff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2b098e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    50, \n",
    "                    epochs=1000,\n",
    "                    validation_data=(X_val, y_val), \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847076ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_unet.utils import plot_segm_history\n",
    "\n",
    "plot_segm_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89f181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1d5c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_unet.utils import plot_imgs\n",
    "\n",
    "plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred, nm_img_to_plot=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5afdbe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0faf44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training(60,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cf401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf761767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training(65,65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4bcf86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "overlay(directories['originals'],directories['masks'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c30a823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf6b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "training(60,4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbeb5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training(64,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4261465b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e02d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa5006b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87843d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "def overlay(original_dir, mask_dir, n):\n",
    "    original_images = os.listdir(original_dir)\n",
    "    mask_images = os.listdir(mask_dir)\n",
    "\n",
    "    for i in range(n):\n",
    "        original_image = random.choice(original_images)\n",
    "        mask_image = original_image.replace('.png', '_mask.png')\n",
    "        if mask_image in mask_images:\n",
    "            img = Image.open(os.path.join(original_dir, original_image))\n",
    "            mask = Image.open(os.path.join(mask_dir, mask_image))\n",
    "            img.paste(mask, (0, 0), mask)\n",
    "            img.show()\n",
    "            #hint: # overlay_masks('original', 'masks', 3) - To plot overlay wiht masks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91cce3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras-unet\n",
    "\n",
    "# import keras\n",
    "# from keras_unet.models import custom_unet\n",
    "\n",
    "# images_file = os.path.join(npy_files, 'original.npy')\n",
    "# labels_file = os.path.join(npy_files, 'mask.npy')\n",
    "\n",
    "# images = np.load(images_file)\n",
    "# labels = np.load(labels_file)\n",
    "\n",
    "# images.shape\n",
    "\n",
    "# # full dataset does not have the last channel\n",
    "# images = images.reshape(images.shape[0],images.shape[1],images.shape[2],1)\n",
    "# labels = labels.reshape(labels.shape[0],labels.shape[1],labels.shape[2],1)\n",
    "\n",
    "# images.shape\n",
    "\n",
    "# p = np.random.permutation(len(images))\n",
    "\n",
    "# images = images[p]\n",
    "# labels = labels[p]\n",
    "\n",
    "# labels = labels.astype(np.float64)\n",
    "\n",
    "# images = images.astype(np.float64)\n",
    "\n",
    "# for i in range(images.shape[0]):\n",
    "#     images[i] = (images[i] - images[i].min()) / (images[i].max() - images[i].min()) # normalize individually\n",
    "\n",
    "\n",
    "# images.shape\n",
    "\n",
    "# X_train = images[0:50]\n",
    "# y_train = labels[0:50]\n",
    "# X_val = images[10:20]\n",
    "# y_val = labels[10:20]\n",
    "# X_test = images[0:]\n",
    "# y_test = labels[0:]\n",
    "\n",
    "# model = custom_unet(\n",
    "#     input_shape=(512, 512, 1),\n",
    "#     use_batch_norm=False,\n",
    "#     num_classes=1,\n",
    "#     filters=32,\n",
    "#     dropout=0.5,\n",
    "#     output_activation='sigmoid')\n",
    "\n",
    "# import keras.optimizers\n",
    "# from keras_unet.metrics import iou, iou_thresholded\n",
    "# from keras_unet.losses import jaccard_distance\n",
    "\n",
    "\n",
    "\n",
    "# opt = keras.optimizer_v1.Adam(lr=0.01)\n",
    "\n",
    "# model.compile(optimizer = 'Adam',    \n",
    "#               loss='binary_crossentropy', \n",
    "#               metrics=[iou, iou_thresholded])\n",
    "\n",
    "# history = model.fit(X_train, \n",
    "#                     y_train, \n",
    "#                     50, \n",
    "#                     epochs=500,\n",
    "#                     validation_data=(X_val, y_val), \n",
    "#                     verbose=1)\n",
    "\n",
    "# from keras_unet.utils import plot_segm_history\n",
    "\n",
    "# plot_segm_history(history)\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# from keras_unet.utils import plot_imgs\n",
    "\n",
    "# plot_imgs(org_imgs=X_test, mask_imgs=y_test, pred_imgs=y_pred, nm_img_to_plot=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef9bf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My next idea in the pipe line is to compare same images on different iterations and come to conclusion.\n",
    "# To decide what batch size and epochs gives the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdb788f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
